
\documentclass[11pt]{article}

\usepackage[latin1]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{url}
\usepackage[breaklinks=true,hyperref]{hyperref}
\usepackage{amssymb}
\usepackage[dvips]{color}
\usepackage{epsfig}
\usepackage{mathrsfs}
\usepackage{indentfirst}
\usepackage{subfig}

\include{header}

\newcommand{\pr}{\text{Pr}}

\newcommand{\bp}{\textsf{BP}}
\newcommand{\strongbp}{\widehat{\textsf{BP}}}
%\newcommand{\strongbp}{\textsf{strongBP}}
\newcommand{\bpp}{\textsf{BPP}}
\newcommand{\parity}{\oplus}
\newcommand{\p}{\textsf{P}}
\newcommand{\op}{\textsf{Op}}
\newcommand{\pp}{\textsf{PP}}
\newcommand{\np}{\textsf{NP}}
\newcommand{\conp}{\textsf{coNP}}
\newcommand{\x}{\textsf{X}}
\newcommand{\intersection}{\textsf{intersect}}
\newcommand{\intersect}{\textsf{intersect}}
\newcommand{\majority}{\textsf{majority}}
\newcommand{\ma}{\textsf{MA}}

\begin{document}

\begin{center} \begin{LARGE} {\sc \bf Amplification with Operators on Complexity Classes} \vspace{6pt}

{\sc 18.405 Final Paper, Spring 2011} \vspace{9pt}

\end{LARGE} { \Large \textsc{Brian Hamrick and Travis Hance}}

\end{center}

\section{Introduction}

Complexity theory is, at its heart, the study of the difficulty of various classes of problems. In order to have a tractible proof setting, complexity theorists usually define a problem by a set of strings which should be accepted, and all others should be rejected. However, many natural problems do not fall into the class of languages, but rather the class of promise problems. A promise problem is usually described as a problem where there is a set of strings that you must accept, a set of strings that you must reject, and a set of strings where it does not matter.

In this paper we work to reproduce several classical complexity theoretic results explicitly in the context of promise problems, which we represent as partial functions. We introduce several operators, based on their analogues for languages and use them to establish analogues of several standard results. In particular, we will prove that probabilities can be amplified, not just in $\bpp$, but in more general classes which contain randomness.

\section{Definitions}

\subsection{Partial Functions}

Complexity classes are usually defined in terms of \emph{languages}. A language $L$ is a subset of $\bigcup_{n=0}^{\infty}\{0,1\}^n$, which can also be viewed as a function $f_L: \bigcup_{n=0}^{\infty}\{0,1\}^n \to \{0,1\}$, where $f_L(x) = 1$ if and only if $x \in L$. However, the definitions of some complexity classes in terms of languages leads to undesirable consequences. For example, the standard definition of $\bpp$ means that a ``$\bpp$-machine'' must accept \emph{every} input with probability outside the range $[\frac{1}{3},\frac{2}{3}]$, but nearly every natural problem whose solution is described as a $\bpp$ algorithm in fact has a promise associated. The concept of a partial function is a natural way to resolve this issue.

\begin{definition}\label{partialfunction}
A \emph{partial function} is a function $f: \bigcup_{n=0}^{\infty}\{0,1\}^n \to \{0,1,\x\}$.
\end{definition}

\subsection{Complexity Classes}

For the entirety of this paper, we will use the following definitions of a complexity class and $\p$.

\begin{definition}\label{complexityclass}
A \emph{complexity class} is a set of partial functions.
\end{definition}

\begin{definition}\label{p}
The complexity class $\p$ is the set of partial functions such that $f \in \p$ if and only if there exists a polynomial $p$ and a Turing machine $T$ such that:
\begin{itemize}
\item If $f(x) = 1$, then $T$ halts after at most $p(|x|)$ steps and accepts.
\item If $f(x) = 0$, then $T$ halts after at most $p(|x|)$ steps and rejects.
\end{itemize}
\end{definition}

Notice that there is no restriction on $T$ if $f(x) = \x$. However, this definition of $\p$ can be reconciled with the standard definition of $\p$ in the following way.

\begin{remark}\label{equivtoold}\emph{
For every partial function $f \in \p$, there exists another partial function $L \in \p$ such that
\begin{itemize}
\item For all $x$, $L(x) = 0$ or $L(x) = 1$.
\item If $f(x) = 1$, then $L(x) = 1$.
\item If $f(x) = 0$, then $L(x) = 0$.
\end{itemize}
}\end{remark}

To see this, consider simulating $T$ and cutting it off after $p(|x|)$ steps, which is followed by a rejection. In this statement, we can see $L$ as a language in the standard complexity class $\p$, so effectively any partial function can be extended to a language.

\subsection{Operators}

In this paper we focus on four operators on complexity classes: $\Sigma, \Pi, \bp, \parity$ which are defined in analogy to the relationship between $\p$ and the classes $\np$, $\conp$, $\bpp$, and $\parity\p$ and based on the operators introduced in \cite{Schoning} and \cite{Schoning2}. For all of these definitions, we let $\langle x, y\rangle$ denote a single string of size $O(|x| + |y|)$ that represents the pair $(x,y)$. Additionally, we define a strengthened version of the $\bp$ operator, $\strongbp$, which guarantees amplification style results. We will show in section \ref{amplifysection} that for most of the classes we consider, these operators give the same result.

\begin{definition}\label{opsigma}
For a complexity class $C$, we define the class $\Sigma \cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then there exists a $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x,y \rangle) = 1$.
\item If $f(x) = 0$ then for every $y \in \{0,1\}^{p(|x|)}$, we have $g(\langle x, y\rangle) = 0$.
\end{itemize}
\end{definition}

\begin{definition}\label{oppi}
For a complexity class $C$, we define the class $\Pi \cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then for every $y \in \{0,1\}^{p(|x|)}$, we have $g(\langle x,y \rangle) = 1$.
\item If $f(x) = 0$ then there exists $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 0$.
\end{itemize}
\end{definition}

\begin{definition}\label{opbp}
For a complexity class $C$, we define the class $\bp\cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 1$ is at least $\frac{2}{3}\cdot 2^{p(|x|)}$.
\item If $f(x) = 0$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 0$ is at least $\frac{2}{3}\cdot 2^{p(|x|)}$.
\end{itemize}
\end{definition}

\begin{definition}\label{opstrongbp}
For a complexity class $C$, we define the class $\strongbp\cdot C$ as the set of partial functions $f$ such that for every polynomial $q(n)$, there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y \rangle) = 1$ is at least \linebreak$\left(1 - \frac{1}{2^{q(|x|)}}\right)\cdot 2^{p(|x|)}$.
\item If $f(x) = 0$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y \rangle) = 0$ is at least \linebreak$\left(1 - \frac{1}{2^{q(|x|)}}\right)\cdot 2^{p(|x|)}$.
\end{itemize}
\end{definition}

\begin{definition}\label{opparity}
For a complexity class $C$, we define the class $\parity\cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then for all $y \in \{0,1\}^{p(|x|)}$, $g(\langle x, y\rangle) \neq \x$ and for an odd number of such $y$, $g(\langle x,y\rangle) = 1$.
\item If $f(x) = 0$ then for all $y \in \{0,1\}^{p(|x|)}$, $g(\langle x, y\rangle) \neq \x$ and for an even number of such $y$, $g(\langle x,y\rangle) = 1$.
\end{itemize}
\end{definition}

In this paper, we will want to concern ourselves mainly with $\p$ and classes that result from applying a sequence of the above operators to it. We will use the following terminology throughout.
\begin{definition}\label{constructible}
For a set $Q$ of operators, we say a complexity class $C$ is \emph{$Q$-constructible} if it is of the form $\op_k \cdot\op_{k-1} \cdots \op_{2} \cdot \op_1 \cdot \p$ for some $k$ where $\op_i \in Q$ for all $i \in \{1,\ldots,k\}$.
\end{definition}

\section{Polynomial Time Reductions}

One of the technical details that will arise in many of our results is the need for polynomial time reductions. In this section, we will establish that all $\{\Sigma,\Pi,\bp,\parity\}$-constructible complexity classes are closed under polynomial time reductions. In particular, we need

\begin{prop}
Let $C$ be a $\{\Sigma,\Pi,\bp,\parity\}$-constructible complexity class and let $T$ be a mapping $\{0,1\}^n \to \{0,1\}^m$ defined by a polynomial time Turing machine. Then if $f \in C$, $f\circ T \in C$.
\end{prop}

This follows from the following lemma:

\begin{lemma}
If $C$ is a complexity class closed under polynomial time reductions. Then $\Sigma \cdot C$, $\Pi\cdot C$, $\bp\cdot C$, and $\parity\cdot C$ are closed under polynomial time reductions.
\end{lemma}
\begin{proof}
We wish to show that if $f \in \op \cdot C$, then $f \circ T \in \op \cdot C$. We have a $g \in C$ such that $g(\langle T(x), y\rangle)$ has the correct relation to $f$ for $f$ to be in $\op \cdot C$ (for example, for $\Sigma$, if $f(T(x)) = 1$, then there is a $y$ with $g(\langle T(x), y\rangle) = 1$ and if $f(T(x)) = 0$, then for all $y$ $g(\langle T(x), y \rangle) = 0$). However, we can construct a polynomial time Turing machine that takes $\langle x, y\rangle$ to $\langle T(x), y\rangle$, so since $C$ is closed under polynomial time reductions, we have that $h(\langle x,y\rangle) = g(\langle T(x),y\rangle)$ is a function in $C$. As $h(\langle x,y\rangle)$ has the same relation to $f \circ T$ as $g$ does to $f$, we have that $f \in \op \cdot C$, as desired.
\end{proof}

\section{Basic Operator Results}

Because we will be working with complexity classes defined by sequences of operators applied to $\p$, it will be useful to have several basic results about manipulations that can be performed with operators. We will start with the ability to collapse two identical operators into one.

\begin{lemma}\label{collapse}
Let $C$ be a complexity class closed under polynomial time reductions. Then $\Sigma\cdot\Sigma\cdot C = \Sigma\cdot C$, $\Pi\cdot\Pi\cdot C = \Pi\cdot C$, $\parity\cdot\parity\cdot C = \parity\cdot C$, and $\strongbp\cdot\strongbp\cdot C = \strongbp \cdot C$.
\end{lemma}
\begin{proof}
We begin with $\Sigma\cdot\Sigma\cdot C = \Sigma\cdot C$. Clearly, we have $\Sigma\cdot C \subseteq \Sigma\cdot\Sigma\cdot C$ as we can ignore the added input $y$. Now let $f$ be a partial function in $\Sigma\cdot\Sigma\cdot C$. Then we have a function $g \in \Sigma \cdot C$ such that if $f(x) = 1$ then there exists $y$ of length $p(|x|)$ such that $g(\langle x,y\rangle) = 1$ and if $f(x) = 1$, then for all such $y$ we have $g(\langle x,y\rangle) = 0$. This in turn means that there is a function $h \in C$ such that if $f(x) = 1$ then there exists $y$ of length $p(|x|)$ and $z$ of length $p'(|x|)$ such that $h(\langle x, y, z\rangle) = 1$ and if $f(x) = 0$ then for all such $y,z$ we have $h(\langle x,y,z\rangle) = 0$. Because $C$ is closed under polynomial time reductions, we can instead write this as the function $h'(\langle x,yz\rangle)$, where $yz$ is the concatenation of $y$ and $z$, and thus has length $p(|x|) + p'(|x|)$, and $h' \in C$.Then if $f(x) = 1$, there exists a string $w$ of length $p(|x|)+p'(|x|)$ such that $h'(\langle x,w\rangle) = 1$ and if $f(x) = 0$, for all such strings $w$ we have $h'(\langle x,w\rangle) = 0$, so $f \in \Sigma \cdot C$.

The proof for $\Pi\cdot\Pi\cdot C = \Pi\cdot C$ is similar, and the proof for $\parity\cdot\parity\cdot C = \parity\cdot C$ goes the same way but noting at the end that the sum of an odd number of odd quantities is odd. The proof of $\strongbp\cdot\strongbp\cdot C = \strongbp\cdot C$ again goes the same way, but this time we make $g$ and $h$ wrong with less than half of the desired error rate, and then do a union bound at the end to ensure that we are correct sufficiently often.
\end{proof}

We will also use the following results that allow in one direction the interchanging of $\strongbp$ with the other operators.

\begin{lemma}\label{interchange}
Let $C$ be a complexity class closed under polynomial time reductions. Then $\Sigma\cdot\strongbp\cdot C \subseteq \strongbp\cdot\Sigma\cdot C$, $\Pi\cdot\strongbp\cdot C \subseteq \strongbp\cdot\Pi\cdot C$, and $\parity\cdot\strongbp\cdot C \subseteq \strongbp\cdot\parity\cdot C$.
\end{lemma}
\begin{proof}
Let us work through the proof for $\Sigma\cdot\strongbp\cdot C$. Let $f \in \Sigma\cdot\strongbp\cdot C$ and let $q$ be a polynomial. Then there exists a polynomial $p$ and $g \in \strongbp\cdot C$ such that if $f(x) = 1$ then there exists $y$ with length $p(|x|)$ such that $g(\langle x, y\rangle) = 1$ and if $f(x) = 0$ then for every $y$ of length $p(|x|)$, we have $g(\langle x, y\rangle) = 0$. Now since $g \in \strongbp\cdot C$, we have a function $h \in C$ and a polynomial $r(|x|)$ such that $h(\langle x,y,z\rangle) = g(\langle x,y\rangle)$ with probability at least $1 - 2^{-(p(|x|)+q(|x|))}$. In particular, if $f(x) = 1$, then there exists a $y$ such that $h(\langle x,y,z\rangle) = 1$ for at least $1-2^{-(p(|x|)+q(|x|))}$ of the $z$, and if $f(x) = 0$, then the total portion of the $(y,z)$ pairs that can have $h(\langle x,y,z\rangle) = 1$ is at most $2^{p(|x|)}\cdot2^{-(p(|x|)+q(|x|))} = 2^{-q(|x|)}$. Therefore, if we choose a $z$ at random, the probability that there is a $y$ with $h(\langle x, y, z\rangle) = 1$ is at most $2^{-q(|x|)}$. We then consider the function $g'(\langle x,z\rangle)$ which is $1$ if there exists a $y$ such that $h(\langle x,y,z\rangle) = 1$ and $0$ otherwise. Clearly $g' \in \Sigma \cdot C$. By the above argument, $g'(\langle x,z\rangle)$ agrees with $f(x)$ with probability at least $2^{-q(|x|)}$. Since this construction works for any $q$, we have $f \in \strongbp \cdot \Sigma \cdot C$.

The other results follow similarly.
\end{proof}

%\section{Closed Under Intersection}
\section{Amplification of $\bp$ to $\strongbp$\label{amplifysection}}

Consider the amplification of the probabilities in the $\bp$ operator. It is well known that\linebreak $\bpp = \bp \cdot \p$ can be amplified; that is, we can replace the error probability of $1/3$ with probabilities exponentially small in the input size. Thus we can write $\bp \cdot \p = \strongbp \cdot \p$. We would like to compare $\bp \cdot C$ to $\strongbp \cdot C$ for more general complexity classes $C$.

\begin{definition}
We say that a complexity class $C$ is \emph{well-structured} if it is $\{\Sigma, \Pi, \bp, \parity\}$-constructible, and the operator $\parity$ does not appear to the left of a $\bp$ operator.
\end{definition}

The aim of this section and the next is to prove the following amplification result:

\begin{theorem}\label{amplify}
Let $C$ be a well-structured complexity class. Then \emph{$\bp \cdot C = \strongbp \cdot C$}.
\end{theorem}

Initially, this may seem to be obviously true for the same reasons that $\bp \cdot \p = \strongbp \cdot \p$. The problem is that amplification requires running some machine which accepts a language in $C$ more than once. This requires the structure of $C$ to allow for such repetitions. In particular, we will find that it is nontrivial when the $\parity$ operator is involved. The fact that we need $C$ to be well-structured rather than just any $\{\Sigma, \Pi, \bp, \parity\}$-constructible class is due to an annoying detail that will come up when we deal with oracles in Section \ref{oracle}. We will cover the non-well-structured case in Section \ref{notwellstruct}.

To show that a class is amplifiable, we need the concept of a majority reduction.
\begin{definition}\label{defmajority}
We say that a complexity class $C$ is \emph{closed under majority reductions} if for any partial function $f \in C$, the partial function $\majority(f)$ defined by
$$\majority(f)(\langle x_1, \ldots, x_k\rangle) = 
\begin{cases}1 & \text{ if the number of $i$ such that }f(x_i) = 1\text{ is at least $\frac{k}{2}$} \\
0 & \text{ if the number of $i$ such that }f(x_i) = 0\text{ is more than $\frac{k}{2}$}\\
\x & \text{ otherwise}
\end{cases}$$
is in $C$.
\end{definition}
Now, we see that majority reductions are exactly what we want for amplification:
\begin{lemma}\label{majorityimpliesamplify}
If $C$ is a complexity class which is closed under majority reductions and polynomial time reductions, then \emph{$f\in\strongbp \cdot C$.}
\end{lemma}
\begin{proof}
This is now the same application of the Chernoff bound which shows that $\bp \cdot \p = \strongbp \cdot \p$. Suppose $f$ is a partial function in $\bp \cdot C$. Then there is a partial function $g$ in $C$ such that $\pr_y [g(\langle x,y\rangle) = f(x)] > 2/3$ if $f(x) \ne \x$, where the length of $y$ is equal to $p(|x|)$ for some polynomial $p$. Let $q$ be a polynomial, where $e^{-q(|x|)}$ is the desired error probability. Let $k = 48q(|x|)$.

Here is how we determine the value $f(x)$ with error probability $e^{-q(|x|)}$. Choose $k$ strings $y_1,y_2,...,y_k$ randomly, then return $h(\langle x, y_1y_2\cdots y_k\rangle) = \majority(g)(\langle \langle x, y_1 \rangle, \langle x, y_2 \rangle, \ldots, \langle x, y_k \rangle \rangle)$. Notice that $h$ can be easily reduced to $\majority(g)$ in polynomial time, and is therefore in $C$.
Let $X_i$ be an indicator variable which is $1$ if $g(\langle x,y_i\rangle)$ agrees with $f(x)$. We have that the $X_i$ are independent Bernoulli random variables with $\pr\left[X_i = 1\right] > \frac{2}{3}$.  Then by the Chernoff bound,
\begin{align*}
\pr\left[\sum X_i \le k/2\right] &= \pr\left[\sum X_i \le (1 - 1/4)(2k/3)\right]\\
&< e^{-(1/4)^2 (2k/3) / 2}\\
&= e^{-q(|x|)} \\
&< 2^{-q(|x|)}
\end{align*}
We can do this for any polynomial $q$, so $f \in \strongbp \cdot C$. Thus, $\bp \cdot C = \strongbp \cdot C$.
\end{proof}

Thus, in order to prove Theorem \ref{amplify}, we just need to show that any well-structured complexity class is closed under majority reductions. In order to show that these are closed under majority reductions, we will need the help of another property:
\begin{definition}\label{defintersection}
We say that a complexity class $C$ is \emph{closed under intersection} if for any partial function $f \in C$, the partial function $\intersect(f)$ defined by
$$\intersect(f)(\langle x_1, \ldots, x_k\rangle) = 
\begin{cases}1 & \text{ if $f(x_i) = 1$ for all $i$} \\
0 & \text{ if there exists some $i$ for which $f(x_i) = 0$}\\
\x & \text{ otherwise}
\end{cases}$$
is in $C$.
%We say that a class $C$ is \emph{closed under intersection} if for any language $L \in C$, the language $\intersection(L) = \{(x_1,...,x_k) : k\in\mathbb{N}, x_i \in L_i ~ \forall i\}$ is in $C$.
\end{definition}
We will demonstrate that all well-structured complexity classes are closed under intersection and under majority reductions. To do this, we will use induction on the number of operators in $C$. Clearly $\p$ is closed under intersection and majority reductions. Thus, the result follows from the following two lemmas:

\begin{lemma}\label{intersectionlemma}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. If $C$ is closed under majority reductions and under intersection, then (i) \emph{$\Sigma \cdot C$}, (ii) \emph{$\Pi \cdot C$}, (iii) \emph{$\bp \cdot C$}, and (iv) \emph{$\parity \cdot C$} are all closed under intersection.
%Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. Then $C$ is closed under intersection.
\end{lemma}

\begin{lemma}\label{amplifymainlemma}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class class. If $C$ is closed under majority reductions, then (i) \emph{$\Sigma \cdot C$}, (ii) \emph{$\Pi \cdot C$}, and (iii) \emph{$\bp \cdot C$} are closed under majority reductions. Furthermore, (iv) \emph{$\parity \cdot C$} is closed under majority reductions if $C$ is $\{\Sigma, \Pi, \parity\}$-constructible.
\end{lemma}
We begin with the proof of Lemma \ref{intersectionlemma}
\begin{proof}[Proof of Lemma \ref{intersectionlemma}]
\begin{enumerate}
\item[]
\item[(i)] Suppose $f$ is a partial function in $\Sigma\cdot C$. Then there exists a partial function $g\in C$ and a polynomial $p$ such that $f(x) = 1$ if there exists some $y$ with $|y| = p(|x|)$ such that $g(\langle x,y\rangle) = 1$, and $f(x) = 0$ if for all $y$ with $|y| = p(|x|)$ we have $g(\langle x, y\rangle) = 0$. Now, we want to show that $\intersect(f) \in \Sigma \cdot C$. Now, $\intersect(f)(\langle x_1,...,x_k\rangle) = 1$ if and only if there exist $y_1,...,y_k$ such that $g(\langle x_i, y_i\rangle) = 1$ for all $i$, which is equivalent to saying that $\intersect(g)(\langle \langle x_1,y_1\rangle,...,\langle x_k,y_k\rangle\rangle) = 1$. Similarly, $\intersect(f)(\langle x_1,...,x_k\rangle) = 0$ if and only if for all $y_1,...,y_k$, we have $\intersect(g)(\langle \langle x_1,y_1\rangle,...,\langle x_k,y_k\rangle\rangle) = 0$. Thus, $\intersect(f) \in \Sigma \cdot C$.

%To do this, we just guess a $k$-tuple $(y_1,y_2,...,y_k)$, and then check if $M$ accepts $(x_1, y_1)$, $(x_2, y_2)$, ..., and $(x_k, y_k)$. This is equivalent to checking that $((x_1,y_1),(x_2,y_2),...,(x_k,y_k)) \in \intersect(M)$, and by assumption, $\intersect(M)$ is in $C$ since $M$ is in $C$.

\item[(ii)] The proof for $\Pi \cdot C$ is analogous to the proof for $\Sigma \cdot C$.

%\item[(iii)] Now we consider $\bp \cdot C$. By assumption, $C$ is closed under majority reductions, so by Lemma \ref{majorityimpliesamplify}, $\bp \cdot C = \strongbp \cdot C$. If we take any language $L \in \bp \cdot C$, we find that $L \in \strongbp \cdot C$. Therefore, there exists a $C$ machine $M$ such that $x\in L$ if and only if
%\begin{center}
%$\displaystyle \pr_y [M(x,y)\text{ accepts}] > $
%\end{center}

\item[(iii)] Now we consider $\bp \cdot C$. Let $f$ be a partial function in $\bp \cdot C$. Then, there is some partial function $g \in C$ and a polynomial $p$ such that $\pr_y[f(x) = g(\langle x,y\rangle)] > 2/3$ if $f(x) \ne \x$, where $y$ is chosen as a random string of length $p(|x|)$.

By assumption, $C$ is closed under majority reductions and under intersection. Thus,\linebreak $\intersect(\majority(g)) \in C$. We want to show that $\intersect(f) \in \bp\cdot C$. For any $(x_1,x_2,...,x_k)$, we randomly choose random strings $y_{i,j}$ of length $p(|x_i|)$, for $1\le i\le k$ and $j\le 1\le \ell$, where $\ell = \lceil -48\ln(1 - (2/3)^{1/k}) \rceil$. Then, we check $\intersect(\majority(g))(\langle X_1, X_2, ..., X_k\rangle)$, where
\begin{center}
$X_i = \langle\langle x_i,y_{i,1}\rangle,\langle x_{i},y_{i,2}\rangle,...,\langle x_{i},y_{i,\ell}\rangle\rangle$.
\end{center}
By the Chernoff bound, as in the proof of Lemma \ref{majorityimpliesamplify}, we have that $\majority(g)(X_i) = f(x_i)$ with probability greater than $e^{-(1/4)^2 (2\ell/3)/2} \ge 1 - (2/3)^{1/k}$. If $f(x_i) = 1$ for all $i$, then the probability that there exists some $i$ for which $\majority(g)(X_i) \ne 1$ is therefore greater than $((2/3)^{1/k})^k = 2/3$. If there is some $i$ for which $f(x_i) = 0$, then there is a $1 - (2/3)^{1/k} \ge 2/3$ chance that $\majority(g)(X_i) = 0$.

Thus, we get that $\intersect(\majority(g))(\langle X_1,...,X_k\rangle) = \intersect(f)(\langle x_1,...,x_k\rangle)$ with probability at least $2/3$. Therefore, since $\intersect(\majority(g)) \in C$, we get that $\intersect(f) \in \bp \cdot C$, so $\bp \cdot C$ is closed under intersection.

%Thus, we get that $(X_1,...,X_k)\in\intersect(\majority(M))$ with probability greater than $2/3$ if $(x_1,x_2,...,x_k)\in L$, and $(X_1,...,X_k)\not\in\intersect(\majority(M))$ with probability greater than $2/3$ if $(x_1,x_2,...,x_k)\not\in L$. Therefore, $\intersect(L) \in \bp \cdot C$, so $\bp \cdot C$ is closed under intersection.

\item[(iv)] Finally, we consider $\parity \cdot C$. If $f \in \parity \cdot C$, then there is a partial function $g \in C$ and a polynomial $p$ such that $f(x) = 1$ if and only if an odd number of $y \in \{0,1\}^{p(|x|)}$ and are such that $g(\langle x, y\rangle) = 1$, and $f(x) = 0$ if and only if there are an even number (but if $g(\langle x,y\rangle) = \x$ for any $y$, then $f(x) = \x$). We want to show that $\intersect(f)$ is in $\parity \cdot C$. Say we have $x_1,x_2,...,x_k$ and we need to verify that all of them are in $f$. Then, accept if there are an odd number of sequences $y_1,y_2,...,y_k$ such that $\intersect(g)(\langle\langle x_1,y_1\rangle,\langle x_2,y_2\rangle,...,\langle x_k,y_k\rangle\rangle) = 1$. To see why this works, let $\# x_i$ be the number of $y_i$ for which $g(\langle x_i,y_i\rangle) = 1$. Then, the number of sequences $y_1,y_2,...,y_k$ for which $\intersect(g)(\langle\langle x_1,y_1\rangle,\langle x_2,y_2\rangle,...,\langle x_k,y_k\rangle\rangle) = 1$ is equal to $(\# x_1)(\# x_2)\cdots(\# x_k)$ which is odd if and only if $\# x_i$ is odd for all $i$.
\end{enumerate}
\end{proof}

\begin{proof}[Proof of Lemma \ref{amplifymainlemma} (i,ii,iii)]

 The proofs of (i), (ii), and (iii) are similar to the proofs in Lemma \ref{intersectionlemma}. Part (iv) is the most difficult, and will not be finished until Section \ref{oracle}.
\begin{enumerate}
\item[(i)] Suppose $f$ is a partial function in $\Sigma\cdot C$. Then there exists a partial function $g\in C$ and a polynomial $p$ such that $f(x) = 1$ if there exists some $y$ with $|y| = p(|x|)$ such that $g(\langle x,y\rangle) = 1$, and $f(x) = 0$ if for all $y$ with $|y| = p(|x|)$ we have $g(\langle x, y\rangle) = 0$. Now, we want to show that $\majority(f) \in \Sigma \cdot C$. Now, $\majority(f)(\langle x_1,...,x_k\rangle) = 1$ if and only if there exist $y_1,...,y_k$ such that $g(\langle x_i, y_i\rangle) = 1$ for at least half of the $i$, which is equivalent to saying that $\majority(g)(\langle \langle x_1,y_1\rangle,...,\langle x_k,y_k\rangle\rangle) = 1$. Similarly, $\majority(f)(\langle x_1,...,x_k\rangle) = 0$ if and only if for more all $y_1,...,y_k$, we have $\majority(g)(\langle \langle x_1,y_1\rangle,...,\langle x_k,y_k\rangle\rangle) = 0$. Thus, $\majority(f) \in \Sigma \cdot C$.

%Suppose $L \in \Sigma \cdot C$. Then there exists a language $M \in C$ and a polynomial $p$ such that $x\in L$ if and only if there exists some $y$ with $|y| = p(x)$ such that $(x,y) \in M$. Now, we want to show that $\intersect(L) \in \Sigma \cdot C$; that is, given a $k$-tuple $(x_1,x_2,...,x_k)$, we want to determine if at least half of the $x_i$ are in $L$ using the power of $\Sigma \cdot C$. To do this, just guess a $k$-tuple $(y_1,y_2,...,y_k)$ with $|y_i| = p(|x_i)|$ and then check if $((x_1,y_1),(x_2,y_2),...,(x_k,y_k)) \in \majority(M)$. Since $C$ is closed under majority reductions, $\majority(M) \in C$. There exists such $y_i$'s if and only if a majority of the $x_i$ are in $L$.
\item[(ii)] The proof for $\Pi \cdot C$ is analogous to the proof for $\Sigma \cdot C$.
\item[(iii)] Now we consider $\bp \cdot C$. Let $f$ be a partial function in $\bp \cdot C$. Then there exists a partial function $g \in C$ and a polynomial $p$ such that if $y \in \{0,1\}^{p(|x|)}$ is chosen as a random string, then $\pr[f(x) = g(\langle x,y\rangle)] > 2/3$ if $f(x) \ne \x$.

%\begin{center}
%$\pr[M\text{ accepts }(x,y)] > 2/3$ if $L$ accepts $x$,\\
%$\pr[M\text{ rejects }(x,y)] > 2/3$ if $L$ rejects $x$.
%\end{center}
For any $\langle x_1,x_2,...,x_k\rangle$, we randomly choose random strings $y_{i,j}$ of length $p(|x_i|)$, for $1\le i\le k$ and $j\le 1\le \ell$, where $\ell = \lceil -48\ln(1 - (2/3)^{1/k}) \rceil$.
Now, $\majority(\majority(g)) \in C$, since $C$ is closed under majority reductions. By the Chernoff bound, (as in Lemma \ref{intersectionlemma}) for any $i$ there is at least a $1-(2/3)^{1/k}$ probability that some $X_i = \langle\langle x_i,y_{i,1}\rangle, \langle x_i, y_{i,2}\rangle,...,\langle x_i, x_{i,\ell}\rangle\rangle$ is ``correct," by which we mean that $\majority(g)(X_i) = f(x_i)$.

Thus, there is at least a $2/3$ chance that \begin{center}$\majority(\majority(g))(\langle X_1,X_2,...,X_k\rangle) = \majority(f)(\langle x_1,x_2,...,x_k\rangle)$.\end{center} Therefore, $\majority(f) \in \bp \cdot C$.
\end{enumerate}
\end{proof}

\section{An Oracle Result}\label{oracle}

To complete the proof of Lemma \ref{amplifymainlemma} (iv), we use the following generalization of a result in \cite{Toda}, which is that $\parity \cdot (\p ^{\parity\cdot\p}) = \parity\cdot\p$, a fact which is used to show that $\parity \cdot \p$ is closed under majority reductions. Proving this fact is the main reason that we need the fact that the $\{\Sigma, \Pi, \bp, \parity\}$-constructible classes are closed under intersection.

\begin{theorem}\label{oracleparityc}
%Let $C$ be a class containing \emph{$\p$} which is closed under intersection. Then\linebreak \emph{$\parity \cdot (\p^{\parity \cdot C}) = \parity \cdot C$}.
%Let $C$ be a $\{\Sigma,\Pi,\parity\}$-constructible class. Then \emph{$ \p^{\parity \cdot C} = \parity \cdot C$}.
Let $C$ be a class which is closed under polynomial reductions and is closed under intersection and such that every function in $C$ can be extended to a function which is defined everywhere (replacing all \emph{$\x$}'s with $0$s and $1$s) which is also in $C$. Then \emph{$ \p^{\parity \cdot C} = \parity \cdot C$}.
\end{theorem}
\begin{proof}
The direction $\parity \cdot C \subseteq \p^{\parity \cdot C}$ is trivial. Let us consider the interesting direction\linebreak $\p^{\parity \cdot C}\subseteq \parity\cdot C$.

Suppose $f \in \parity \cdot (P^{\parity\cdot C})$. We can assume without loss of generality that $f$ is defined everywhere (i.e. $f(x) \ne \x$ for all $x$). If $f$ was not defined somewhere, we could extend it to some $\overline{f}$ which is defined everywhere and agrees with $f$ everywhere that $f$ is defined. Then we could show that $\overline{f} \in \parity \cdot C$, and then we would have $f \in \parity \cdot C$.

Thus, we now assume that $f$ is defined everywhere. Then, there is some polynomial time turing machine $T$, equipped with an oracle to some function $g\in \parity\cdot C$, which accepts $x$ if $f(x) = 1$ and rejects $x$ if $f(x) = 0$.

To show that $f$ lies in $\parity\cdot C$, the basic idea is to ``guess" the answers to the oracle calls, and then check them. We make it so that we get an odd number of solutions whenever we guess correctly, and an even number of solutions otherwise.

%We use instead a Turing machine $T'$ which makes oracle calls to the language $M'$, defined as follows. For an input $x$, with $|x| \ge 2$, $M'$ accepts $x$ if either
%\begin{itemize}
%\item $x$ consists only of $0$'s.
%\item $x$ begins with a $1$, and $M$ would accept the last $|x| - 2$ bits.
%\end{itemize}
There exists a polynomial $p$ such that $T$ always makes at most $p(|x|)$ oracle calls. There is a polynomial $q(|x|)$ which bounds the input length of any query made to an oracle.

The $i^\text{th}$ oracle call queries some input $x_i$ to check if $g(x_i) = 1$. There is a function $h \in C$ and a polynomial $r$ such that for any query string $x_i$, we have $g(x_i) = 1$ if and only if $h(\langle x_i,y\rangle) = 1$ for an odd number of $y\in\{0,1\}^{r(|x|)}$, and $g(x_i) = 0$ otherwise. Thus, $f \in \parity \cdot C$.

To show that $f$ is in $\parity \cdot C$, we guess the following bits for a given input $x$:
\begin{itemize}
\item Bits $a_1,a_2,...,a_{p(|x|)}$. Intuitively, these will be the answers to the oracle calls made by $T$.
\item Bits $b_1,b_2,...,b_{p(|x|)}$. The purpose of these will become clear later; they will be necessary for fixing the parity of some numbers.
\item Strings $y_1,y_2,...,y_{p(|x|)}$, each of length $r(q(|x|))$. These are the strings that an oracle call guesses.
\end{itemize}
After guessing, we do the following polynomial time reduction to $\intersect(h)$. For an input $x$, simulate $T$ using the bits $a_1,a_2,...,a_{p(|x|)}$ as the answers to the oracle calls (taking $1$ to mean that the oracle call accepted, and $0$ to mean that the oracle call rejected). If $T$ would reject, then reject.

Also find the strings $x_1,x_2,...,x_{p(|x|)}$ which are the inputs that $T$ would query to the oracles. These may depend on the $a_i$. We now want to verify that the oracle calls are correct. Say that $(a_i, b_i, y_i)$ is \emph{good} if either
\begin{itemize}
\item $b_i = 0$, and both $a_i = 0$ and $y_i = 0^{r(q(|x|))}$, or
\item $b_i = 1$ and $h(x_i, y_i)$.
\end{itemize}
Reject if any $(a_i, b_i, y_i)$ is not good. To determine if they are all good, we will have to check some pairs $(x_i, y_i)$ to see if $h(x_i,y_i) = 1$. We can do this with a call to $\intersect(h)$.

(Technical note: it is possible that some bits out of the $a_i$, $b_i$, and $y_i$ are not used. It is possible that not all $p(x)$ oracle calls will be made, or that not all $r(q(|x|))$ bits of a $y_i$ will be used, if $|x_i| < q(|x|)$. Thus, we require that all unused bits be $0$ for $(a_i, b_i, y_i)$ to be good. In that case that there is no $i^\text{th}$ oracle call, the only good triple $(a_i, b_i, y_i)$ is the all zeroes triple.)

Why does this give us what we want? We want to show that this will accept for an odd number of choices of the $a_i$, $b_i$, and $y_i$ if and only if $f(x) = 1$. Let $\# (a_1,...,a_{p(|x|)})$ be the number of ways to choose the $b_i$, and $y_i$ such that all triples $(a_i,b_i,y_i)$ are good. Then the total number of accepting paths is
\begin{center}$\displaystyle \sum_{a_1,...,a_{p(|x|)}\text{ such that $T$ accepts}}  \#(a_1,...,a_{p(|x|)})$\end{center}
We claim that $ \#(a_1,...,a_{p(|x|)})$ is odd if and only if $a_1,a_2,...,a_{p(|x|)}$ are the correct answers to the oracle calls. This follows from the way we chose to decide if $(a_i, b_i, y_i)$ is good. If $a_1,a_2,...,a_{p(|x|)}$ are the correct answers to the oracle calls, then for each $i$, there are an odd number of $(b_i,y_i)$ such that $(a_i, b_i, y_i)$ is good. If $a_i = 1$, all good triples will have $b_i = 1$, so the parity is determined by the number of $y_i$ for which $h(x_i, y_i)=1$. But since $a_i = 1$, then this should be odd. In the other case, if $a_i = 0$, then the number of $y_i$ for which $h(x_i, y_i)=1$ is even. However, we get one more good pair, namely $(0,0,0)$.

On the other hand, if any $a_i$ is incorrect, then the first such incorrect answer will have an even number of good triples.

Hence, the sum will be odd if and only if $T$ accepts when the oracle calls are correct. Therefore, $f(x) = 1$ if and only if this accepts for an odd number of choices of all the $a_i$, $b_i$, and $y_i$.
%Hence, the sum will be odd if and only if $T$ accepts when the oracle calls are correct. Therefore, $L$ accepts $x$ if and only if this accepts for an odd number of choices of all the $a_i$, $b_i$, and $y_i$, and $L$ rejects $x$ otherwise. Thus, $L \in \parity \cdot C$. This is true for any $L \in \p^{\parity \cdot C}$, so $\p^{\parity \cdot C} \subseteq \parity \cdot C$.
\end{proof}
%\begin{remark}\emph{
%While this paper applies Theorem \ref{oracle} only in the case where $C$ is $\{\Sigma,\Pi,\bp,\parity\}$-constructible, it can also be used to show, for instance, that $\p^{\parity \cdot \pp} = \parity \cdot \pp$, although it is nontrivial to show that $\pp$ is closed under intersection. For a proof, see \cite{Beigel}.
%}\end{remark}

We can use this remarkable fact to finish the proof of Lemma \ref{amplifymainlemma}, thus proving Theorem \ref{amplify}.
\begin{proof}[Proof of Lemma \ref{amplifymainlemma} (iv)]
Since $C$ is $\{\Sigma,\Pi,\parity\}$-constructible, it is the case that any function in $C$ can be extended to be defined everywhere. To see this, we simply take any function in $C$ and extend its innermost $\p$ function (see Remark \ref{equivtoold}), giving us the entire definition. The $\Sigma$, $\Pi$, and $\parity$ operators all have the property that they can precisely define a function given the one on the next level. Therefore, by Theorem \ref{oracleparityc}, we have that $\p^{\parity\cdot C} = \parity\cdot C$.

Now, we will show that $\majority(f)$ is in $\parity \cdot C$. It is easy to see that $\majority(f) \in \p^{\parity \cdot C}$. For a given $k$-tuple $(x_1,x_2,...,x_k)$, we use the oracle call to $\parity \cdot C$ to determine how many of the $x_i$ are such that $f(x) = 1$ and how many are such that $f(x) = 0$. If at least half are accepted, we accept, and if more than half are rejected, we reject.

Thus, $\majority(f) \in  \p^{\parity \cdot C}$, so $\majority(f) \in \parity \cdot C$. Therefore, $\parity \cdot C$ is closed under intersection.
%Take any function $f \in \parity \cdot C$. If $C$ is $\{\Sigma, \Pi, \parity\}$-constructible, we can extend $f$ to some $\overline{f}$ which is defined everywhere; i.e. $\overline{f}(x) \ne \x$ for all $x$. To extend $f$ in this way, we simply extend the innermost $\p$ function (see Remark \ref{equivtoold}).
%
%Now, we will show that $\majority(\overline{f})$ is in $\parity \cdot C$. It is easy to see that $\majority(\overline{f}) \in \p^{\parity \cdot C}$. For a given $k$-tuple $(x_1,x_2,...,x_k)$, we use the oracle call to $\parity \cdot C$ to determine how many of the $x_i$ are such that $\overline{f}(x) = 1$ and how many are such that $\overline{f}(x) = 0$. If at least half are accepted, we accept, and if more than half are rejected, we reject.
%
%Thus, $\majority(\overline{f}) \in \p^{\parity \cdot C}$. Thus, we can apply Theorem \ref{oracleparityc} to get that $\majority(\overline{f}) \in \parity \cdot C$. But $\majority(\overline{f})$ is just an extension of $\majority(f)$, so $\majority(f) \in \parity \cdot C$. Therefore $\parity \cdot C$ is closed under majority reductions.
\end{proof}

\section{The non-well-structured case}\label{notwellstruct}

Theorem \ref{amplify} tells us that for any well-structured class $C$, we have $\bp\cdot C = \strongbp\cdot C$. In this section we will extend it to the following generalization.

\begin{theorem}\label{fullamplify}
If $C$ is a $\{\Sigma,\Pi,\bp,\parity\}$-constructible complexity class, then $\bp\cdot C = \strongbp\cdot C$.
\end{theorem}
\begin{proof}
If $C$ is well-structured, then Theorem \ref{amplify} gives us the result. Now suppose that $C$ is not well-structured. Then $C$ is of the form $Q_k\cdot Q_{k-1}\cdots Q_1\cdot \p$, where for some $i,j$ with $i < j$ we have $Q_i = \bp$ and $Q_j = \parity$. We claim that $\strongbp \cdot C = \strongbp \cdot \parity \cdot \p$. We can then easily see that $\strongbp \cdot \parity \cdot \p \subseteq \strongbp \cdot C$, as we can ignore the other quantifiers easily. By a slight generalization of a result in \cite{Toda}, we have that a $\Sigma$ or $\Pi$ operator can be simulated by the combination of operators $\strongbp \cdot \parity$. As a result, we see that $\strongbp \cdot C \subseteq \strongbp \cdot Q_k \cdots Q_1 \cdot \p$, where at least one of the $Q_i$ is $\parity$. and all of the $Q_i$ are either $\strongbp, \bp$, or $\parity$.

Now consider the smallest $i$ such that $Q_i = \bp$ or $Q_i = \strongbp$. Then all the ones to the right are $\parity$, so we can collapse them down to one $\parity$ operator by Lemma \ref{collapse} and the class that $Q_i$ operates on is well-structured. As a result, we may replace $Q_i$ with $\strongbp$ by Theorem \ref{amplify}. If $Q_{i+1} = \parity$, then by Lemma \ref{interchange}, we can interchange $Q_i$ and $Q_{i+1}$ and obtain a superset of our original class. We continue doing this until $Q_{i+1} = \bp$ or $Q_{i+1} = \strongbp$. If $Q_{i+1} = \strongbp$, we can collapse the two by Lemma \ref{collapse}. If $Q_{i+1} = \bp$, then we note that at this point we have moved the only $\strongbp$ operator to the left of all the $\parity$ operators, so we can replace it by a $\bp$ and this class is well-structured. Therefore, by Theorem \ref{amplify}, we can replace $Q_{i+1}$ and $Q_i$ by $\strongbp$, and then by Lemma \ref{collapse}, we may collapse them into one. Continuing in this way, we eventually collapse the entire string of operators into just two, and obtain the result that $\strongbp \cdot C \subseteq \strongbp \cdot \parity \cdot \p$.

Now the result is simple, as $\parity \cdot \p$ is well-structured, so by Theorem \ref{amplify}, we have $\strongbp\cdot\parity\cdot\p = \bp\cdot\parity\cdot\p \subseteq \bp\cdot C$. Therefore we have shown that $\bp \cdot C \subseteq \strongbp \cdot C$, and clearly $\strongbp \cdot C \subseteq \bp \cdot C$, so $\bp\cdot C = \strongbp \cdot C$, as desired.
\end{proof}

\section{Conclusion}

The results from this paper show that the view of complexity of promise problems, or alternatively the complexity of partial functions, leads to results of similar interest to those that result from the study of languages. Additionally, partial functions offer very natural definitions for operators, especially randomized operators, on complexity classes. Our work does suggest several directions for futuer work.
Some of these might include developing similar groundwork for different contexts, such as operators for quantum complexity classes, function classes, or for classes that are smaller than $\p$ or larger than $\textsf{PSPACE}$. Additionally, it could be interesting to consider other operators in this context, such as $\mod k$ for general $k$, and their relationships to the ones we define here.

\pagebreak

\begin{thebibliography}{9}

%\bibitem{Beigel} Beigel, R., Reingold, N., and Spielman, D.A. \emph{PP is closed under intersection}, Proceedings of ACM Symposium on Theory of Computing 1991, pp. 1-9, 1991.

\bibitem{Schoning} Sch\"oning, U. \emph{Probabilitistic complexity classes and lowness}, Proceedings of the 2nd IEEE Conference on Structure in Complexity Theory, 1987, pp. 2-8.

\bibitem{Schoning2} Sch\"oning, U. \emph{The power of counting}, Proceedings of the 3rd IEEE Conference on Structure in Complexity Theory, 1988, pp. 2-9.

\bibitem{Toda}Toda, S. \emph{PP is as Hard as the Polynomial-Time Hierarchy.} Siam Journal of Computing. Vol. 20, No. 5, pp. 865-877. Oct 1991.

\bibitem{Toda2} Toda, S. and Ogiwara, M. \emph{Counting classes are at least as hard as the polynomial-time hierarchy,} Structure in Complexity Theory Conference, 1991, Proceedings of the Sixth Annual, pp. 2-12, 30 Jun-3 Jul 1991.

\end{thebibliography}

\end{document}

