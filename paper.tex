
\documentclass[11pt]{article}

\usepackage[latin1]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{url}
\usepackage[breaklinks=true,hyperref]{hyperref}
\usepackage{amssymb}
\usepackage[dvips]{color}
\usepackage{epsfig}
\usepackage{mathrsfs}
\usepackage{indentfirst}
\usepackage{subfig}

\include{header}

\newcommand{\pr}{\text{Pr}}

\newcommand{\bp}{\textsf{BP}}
\newcommand{\strongbp}{\widehat{\textsf{BP}}}
%\newcommand{\strongbp}{\textsf{strongBP}}
\newcommand{\bpp}{\textsf{BPP}}
\newcommand{\parity}{\oplus}
\newcommand{\p}{\textsf{P}}
\newcommand{\op}{\textsf{Op}}
\newcommand{\pp}{\textsf{PP}}
\newcommand{\x}{\textsf{X}}
\newcommand{\intersection}{\textsf{intersect}}
\newcommand{\intersect}{\textsf{intersect}}
\newcommand{\majority}{\textsf{majority}}

\begin{document}

\begin{center} \begin{LARGE} {\sc \bf Amplification with Operators on Complexity Classes} \vspace{6pt}

{\sc 18.405 Final Paper, Spring 2011} \vspace{9pt}

\end{LARGE} { \Large \textsc{Brian Hamrick and Travis Hance}}

\end{center}

\section{Introduction}

\section{Definitions}

\subsection{Partial Functions}

Complexity classes are usually defined in terms of \emph{languages}. A language $L$ is a subset of $\bigcup_{n=0}^{\infty}\{0,1\}^n$, which can also be viewed as a function $f_L: \bigcup_{n=0}^{\infty}\{0,1\}^n \to \{0,1\}$, where $f_L(x) = 1$ if and only if $x \in L$. However, the definitions of some complexity classes in terms of languages leads to undesirable consequences. For example, the standard definition of $\bpp$ means that a ``$\bpp$-machine'' must accept \emph{every} input with probability outside the range $[\frac{1}{3},\frac{2}{3}]$, but nearly every natural problem whose solution is described as a $\bpp$ algorithm in fact has a promise associated. The concept of a partial function is a natural way to resolve this issue.

\begin{definition}\label{partialfunction}
A \emph{partial function} is a function $f: \bigcup_{n=0}^{\infty}\{0,1\}^n \to \{0,1,\x\}$.
\end{definition}

\subsection{Complexity Classes}

For the entirety of this paper, we will use the following definitions of a complexity class and $\p$.

\begin{definition}\label{complexityclass}
A \emph{complexity class} is a set of partial functions.
\end{definition}

\begin{definition}\label{p}
The complexity class $\p$ is the set of partial functions such that $f \in \p$ if and only if there exists a polynomial $p$ and a Turing machine $T$ such that:
\begin{itemize}
\item If $f(x) = 1$, then $T$ halts after at most $p(|x|)$ steps and accepts.
\item If $f(x) = 0$, then $T$ halts after at most $p(|x|)$ steps and rejects.
\end{itemize}
\end{definition}

Notice that there is no restriction on $T$ if $f(x) = \x$. However, this definition of $\p$ can be reconciled with the standard definition of $\p$ in the following way.

\begin{remark}
For every partial function $f \in \p$, there exists another partial function $L \in \p$ such that
\begin{itemize}
\item For all $x$, $L(x) = 0$ or $L(x) = 1$.
\item If $f(x) = 1$, then $L(x) = 1$.
\item If $f(x) = 0$, then $L(x) = 0$.
\end{itemize}
\end{remark}

To see this, consider simulating $T$ and cutting it off after $p(|x|)$ steps, which is followed by a rejection. In this statement, we can see $L$ as a language in the standard complexity class $\p$, so effectively any partial function can be extended to a language.

\subsection{Operators}

%\section{Closed Under Intersection}
\section{Amplification of $\bp$ to $\strongbp$}

Consider the amplification of the probabilities in the $\bp$ operator. It is well known that\linebreak $\bpp = \bp \cdot \p$ can be amplified; that is, we can replace the error probability of $1/3$ with probabilities exponentially small in the input size. Thus we can write $\bp \cdot \p = \strongbp \cdot \p$. We would like to compare $\bp \cdot C$ to $\strongbp \cdot C$ for more general complexity classes $C$.

The aim of this section is to prove the following amplification result:

\begin{theorem}\label{amplify}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. Then \emph{$\bp \cdot C = \strongbp \cdot C$}.
\end{theorem}
Initially, this may seem to be obviously true for the same reasons that $\bp \cdot \p = \strongbp \cdot \bp$. The problem is that amplification requires running some machine which accepts a language in $C$ more than once. This requires the structure of $C$ to allow for such repetitions. This brings us to the concept of majority reductions.
\begin{definition}\label{defmajority}\emph{
We say that a complexity class $C$ is \emph{closed under majority reductions} if for any language $L$, the language $\majority(L) = \{(x_1,...,x_k) : k \in \mathbb{N}, |\{x_i : x_i \in L\}| \ge k/2\}$ is in $C$.
}\end{definition}
Now, we see that majority reductions are exactly what we want for amplification:
\begin{lemma}\label{majorityimpliesamplify}
If $C$ is a complexity class which is closed under majority reductions, then\linebreak \emph{$\bp \cdot C = \strongbp \cdot C$.}
\end{lemma}
\begin{proof}
This is now the same application of the Chernoff bound which shows that $\bp \cdot \p = \strongbp \cdot \p$. Suppose $L$ is a language in $\bp \cdot C$. Then there is a language $M$ in $C$ such that $\pr_y [(x,y) \in M] > 2/3$ if $x\in L$ and $\pr_y [(x,y)\in M] < 1/3$ if $x\not\in L$, where the length of $y$ is polynomial in the length of $x$. Let $q$ be a polynomial, where $e^{-q(|x|)}$ is the desired error probability. Let $k = 48q(|x|)$.

Here is how we determine if a string $x$ is in $L$ with error probability $e^{-q(|x|)}$. Choose $k$ strings $y_1,y_2,...,y_k$ randomly. Then accept if a majority of $(x,y_1),(x,y_2),...,(x,y_k)$ are in $M$, which is possible to do since $\majority(M) \in C$. Let $X_i$ be an indicator variable which is $1$ if $(x,y_i)$ is in $M$. Then by the Chernoff bound,
\begin{align*}
\pr\left[\sum X_i < k/2\right] &= \pr\left[\sum X_i < (1 - 1/4)(2k/3)\right]\\
&< e^{-(1/4)^2 (2k/3) / 2}\\
&= e^{-q(|x|)}
\end{align*}
We can do this for any polynomial $q$, so $L \in \strongbp \cdot C$. Hence, $\bp \cdot C = \strongbp \cdot C$.
\end{proof}

Thus, in order to prove Theorem \ref{amplify}, we just need to show that any \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class is closed under majority reductions. In order to show that these are closed under majority reductions, we will need the help of another property:
\begin{definition}\label{defintersection}
We say that a class $C$ is \emph{closed under intersection} if for any language $L \in C$, the language $\intersection(L) = \{(x_1,...,x_k) : k\in\mathbb{N}, x_i \in L_i ~ \forall i\}$ is in $C$.
\end{definition}
We will demonstrate that all $\{\Sigma, \Pi, \bp, \parity\}$-constructible complexity classes are closed under intersection and under majority reductions. To do this, we will use induction on the number of operators in $C$. Clearly $\p$ is closed under intersection and majority reductions. Thus, the result follows from the following two lemmas:

\begin{lemma}\label{intersectionlemma}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. If $C$ is closed under majority reductions and under intersection, then (i) \emph{$\Sigma \cdot C$}, (ii) \emph{$\Pi \cdot C$}, (iii) \emph{$\bp \cdot C$}, and (iv) \emph{$\parity \cdot C$} are all closed under intersection.
%Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. Then $C$ is closed under intersection.
\end{lemma}

\begin{lemma}\label{amplifymainlemma}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. If $C$ is closed under majority reductions, then (i) \emph{$\Sigma \cdot C$}, (ii) \emph{$\Pi \cdot C$}, (iii) \emph{$\bp \cdot C$}, and (iv) \emph{$\parity \cdot C$} are all closed under majority reductions.
\end{lemma}
We begin with the proof of Lemma \ref{intersectionlemma}
\begin{proof} \emph{(Lemma \ref{intersectionlemma})}
\begin{enumerate}
\item[(i)] Suppose $L \in \Sigma\cdot C$. Then there exists a language $M\in C$ such that $x \in L$ if and only if there exists some $y$ (of length polynomial in the length of $x$) such that $(x, y)\in M$. Now, we want to construct a $\Sigma \cdot C$ machine for $\intersect(L)$; that is, given a $k$-tuple $(x_1,x_2,...,x_k)$, we want to determine if all $x_i$ are in $L$. To do this, we just guess a $k$-tuple $(y_1,y_2,...,y_k)$, and then check if $M$ accepts $(x_1, y_1)$, $(x_2, y_2)$, ..., and $(x_k, y_k)$. This is equivalent to checking that $((x_1,y_1),(x_2,y_2),...,(x_k,y_k)) \in \intersect(M)$, and by assumption, $\intersect(M)$ is in $C$ since $M$ is in $C$.

\item[(ii)] The proof for $\Pi \cdot C$ is analogous to the proof for $\Sigma \cdot C$.

\item[(iii)] Now we consider $\bp \cdot C$. By assumption, $C$ is closed under majority reductions, so by Lemma \ref{majorityimpliesamplify}, $\bp \cdot C = \strongbp \cdot C$. If we take any language $L \in \bp \cdot C$, we find that $L \in \strongbp \cdot C$. Therefore, there exists a $C$ machine $M$ such that $x\in L$ if and only if
\begin{center}
$\displaystyle \pr_y [M(x,y)\text{ accepts}] > $
\end{center}

\item[(iv)] Finally, we consider $\parity \cdot C$. If $L \in \parity \cdot C$, then there is a language $M \in C$ such that $x\in L$ if and only if an odd number of $(x,y)$ are in $M$, where, again, $y$ is polynomial length in the length of $x$. We want to show that $\intersect(L)$ is in $\parity \cdot C$. Say we have $x_1,x_2,...,x_k$ and we need to verify that all of them are in $L$. Then, guess $y_1,y_2,...,y_k$ and see if $((x_1,y_1),(x_2,y_2),...,(x_k,y_k))$ is in $\intersect(M)$. Accept if there are an odd number of sequences $y_1,y_2,...,y_k$ for which this accepts. To see why this works, let $\# x_i$ be the number of $y_i$ for which $(x_i, y_i) \in M$. Then, the number of sequences $y_1,y_2,...,y_k$ which will accept is equal to $(\# x_1)(\# x_2)...(\# x_k)$ which is odd if and only if $\# x_i$ is odd for all $i$.
\end{enumerate}
\end{proof}

\begin{proof} \emph{(Lemma \ref{amplifymainlemma})}

We consider (i), (ii), (iii), and (iv) separately. Part (iv) is the most difficult, and will not be finished until Section \ref{oracle}.
\end{proof}

\section{An Oracle Result}\label{oracle}

To complete the proof of Lemma \ref{amplifymainlemma} (b-iv), we use the following generalization of a result in \cite{Toda}, which shows that $\parity \cdot (\p ^{\parity\cdot\p}) = \parity\cdot\p$, a fact which is used to show that $\parity \cdot \p$ is closed under majority reductions.

\begin{theorem}\label{oracleparityc}
Let $C$ be a class containing \emph{$\p$} which is closed under intersection. Then\linebreak \emph{$\parity \cdot (\p^{\parity \cdot C}) = \parity \cdot C$}.
\end{theorem}
\begin{proof}
The direction $\parity \cdot C \subseteq \parity \cdot (\p^{\parity \cdot C})$ is trivial. Let us consider the interesting direction\linebreak $\parity \cdot (\p^{\parity \cdot C})\subseteq \parity\cdot C$.
\end{proof}
\begin{remark}\emph{
While this paper applies Theorem \ref{oracle} only in the case where $C$ is $\{\Sigma,\Pi,\bp,\parity\}$-constructible, it can also be used to show, for instance, that $\parity \cdot (\p^{\parity \cdot \pp}) = \parity \cdot \pp$, although it is nontrivial to show that $\pp$ is closed under intersection. For a proof, see \cite{Beigel}.
}\end{remark}

\section{Conclusion}

\pagebreak

\begin{thebibliography}{9}

\bibitem{Beigel} Beigel, R., Reingold, N., and Spielman, D.A. \emph{PP is closed under intersection}, Proceedings of ACM Symposium on Theory of Computing 1991, pp. 1-9, 1991.

\bibitem{Toda}Toda, S. \emph{PP is as Hard as the Polynomial-Time Hierarchy.} Siam Journal of Computing. Vol. 20, No. 5, pp. 865-877. Oct 1991.

\bibitem{Toda2} Toda, S. and Ogiwara, M. \emph{Counting classes are at least as hard as the polynomial-time hierarchy,} Structure in Complexity Theory Conference, 1991, Proceedings of the Sixth Annual, pp. 2-12, 30 Jun-3 Jul 1991.

\end{thebibliography}

\end{document}

