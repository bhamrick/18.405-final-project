
\documentclass[11pt]{article}

\usepackage[latin1]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{url}
\usepackage[breaklinks=true,hyperref]{hyperref}
\usepackage{amssymb}
\usepackage[dvips]{color}
\usepackage{epsfig}
\usepackage{mathrsfs}
\usepackage{indentfirst}
\usepackage{subfig}

\include{header}

\newcommand{\pr}{\text{Pr}}

\newcommand{\bp}{\textsf{BP}}
\newcommand{\strongbp}{\widehat{\textsf{BP}}}
%\newcommand{\strongbp}{\textsf{strongBP}}
\newcommand{\bpp}{\textsf{BPP}}
\newcommand{\parity}{\oplus}
\newcommand{\p}{\textsf{P}}
\newcommand{\op}{\textsf{Op}}
\newcommand{\pp}{\textsf{PP}}
\newcommand{\np}{\textsf{NP}}
\newcommand{\conp}{\textsf{coNP}}
\newcommand{\x}{\textsf{X}}
\newcommand{\intersection}{\textsf{intersect}}
\newcommand{\intersect}{\textsf{intersect}}
\newcommand{\majority}{\textsf{majority}}

\begin{document}

\begin{center} \begin{LARGE} {\sc \bf Amplification with Operators on Complexity Classes} \vspace{6pt}

{\sc 18.405 Final Paper, Spring 2011} \vspace{9pt}

\end{LARGE} { \Large \textsc{Brian Hamrick and Travis Hance}}

\end{center}

\section{Introduction}

Complexity theory is, at its heart, the study of the difficulty of various classes of problems. In order to have a tractible proof setting, complexity theorists usually define a problem by a set of strings which should be accepted, and all others should be rejected. However, many natural problems do not fall into the class of languages, but rather the class of promise problems. A promise problem is usually described as a problem where there is a set of strings that you must accept, a set of strings that you must reject, and a set of strings where it does not matter.

In this paper we work to reproduce several classical complexity theoretic results explicitly in the context of promise problems, which we represent as partial functions. We introduce several operators, based on their analogues for languages and use them to establish analogues of several standard results. In particular, we will prove that probabilities can be amplified, not just in $\bpp$, but in more general classes which contain randomness.

\section{Definitions}

\subsection{Partial Functions}

Complexity classes are usually defined in terms of \emph{languages}. A language $L$ is a subset of $\bigcup_{n=0}^{\infty}\{0,1\}^n$, which can also be viewed as a function $f_L: \bigcup_{n=0}^{\infty}\{0,1\}^n \to \{0,1\}$, where $f_L(x) = 1$ if and only if $x \in L$. However, the definitions of some complexity classes in terms of languages leads to undesirable consequences. For example, the standard definition of $\bpp$ means that a ``$\bpp$-machine'' must accept \emph{every} input with probability outside the range $[\frac{1}{3},\frac{2}{3}]$, but nearly every natural problem whose solution is described as a $\bpp$ algorithm in fact has a promise associated. The concept of a partial function is a natural way to resolve this issue.

\begin{definition}\label{partialfunction}
A \emph{partial function} is a function $f: \bigcup_{n=0}^{\infty}\{0,1\}^n \to \{0,1,\x\}$.
\end{definition}

\subsection{Complexity Classes}

For the entirety of this paper, we will use the following definitions of a complexity class and $\p$.

\begin{definition}\label{complexityclass}
A \emph{complexity class} is a set of partial functions.
\end{definition}

\begin{definition}\label{p}
The complexity class $\p$ is the set of partial functions such that $f \in \p$ if and only if there exists a polynomial $p$ and a Turing machine $T$ such that:
\begin{itemize}
\item If $f(x) = 1$, then $T$ halts after at most $p(|x|)$ steps and accepts.
\item If $f(x) = 0$, then $T$ halts after at most $p(|x|)$ steps and rejects.
\end{itemize}
\end{definition}

Notice that there is no restriction on $T$ if $f(x) = \x$. However, this definition of $\p$ can be reconciled with the standard definition of $\p$ in the following way.

\begin{remark}\label{equivtoold}\emph{
For every partial function $f \in \p$, there exists another partial function $L \in \p$ such that
\begin{itemize}
\item For all $x$, $L(x) = 0$ or $L(x) = 1$.
\item If $f(x) = 1$, then $L(x) = 1$.
\item If $f(x) = 0$, then $L(x) = 0$.
\end{itemize}
}\end{remark}

To see this, consider simulating $T$ and cutting it off after $p(|x|)$ steps, which is followed by a rejection. In this statement, we can see $L$ as a language in the standard complexity class $\p$, so effectively any partial function can be extended to a language.

\subsection{Operators}

In this paper we focus on four operators on complexity classes: $\Sigma, \Pi, \bp, \parity$ which are defined in analogy to the relationship between $\p$ and the classes $\np$, $\conp$, $\bpp$, and $\parity\p$ and based on the operators introduced in \cite{Schoning} and \cite{Schoning2}. For all of these definitions, we let $\langle x, y\rangle$ denote a single string of size $O(|x| + |y|)$ that represents the pair $(x,y)$. Additionally, we define a strengthened version of the $\bp$ operator, $\strongbp$, which guarantees amplification style results. We will show in section \ref{amplifysection} that for most of the classes we consider, these operators give the same result.

\begin{definition}\label{opsigma}
For a complexity class $C$, we define the class $\Sigma \cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then there exists a $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x,y \rangle) = 1$.
\item If $f(x) = 0$ then for every $y \in \{0,1\}^{p(|x|)}$, we have $g(\langle x, y\rangle) = 0$.
\end{itemize}
\end{definition}

\begin{definition}\label{oppi}
For a complexity class $C$, we define the class $\Pi \cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then for every $y \in \{0,1\}^{p(|x|)}$, we have $g(\langle x,y \rangle) = 1$.
\item If $f(x) = 0$ then there exists $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 0$.
\end{itemize}
\end{definition}

\begin{definition}\label{opbp}
For a complexity class $C$, we define the class $\bp\cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 1$ is at least $\frac{2}{3}\cdot 2^{p(|x|)}$.
\item If $f(x) = 0$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 0$ is at least $\frac{2}{3}\cdot 2^{p(|x|)}$.
\end{itemize}
\end{definition}

\begin{definition}\label{opstrongbp}
For a complexity class $C$, we define the class $\strongbp\cdot C$ as the set of partial functions $f$ such that for every polynomial $q(n)$, there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y \rangle) = 1$ is at least \linebreak$\left(1 - \frac{1}{2^{q(|x|)}}\right)\cdot 2^{p(|x|)}$.
\item If $f(x) = 0$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y \rangle) = 0$ is at least \linebreak$\left(1 - \frac{1}{2^{q(|x|)}}\right)\cdot 2^{p(|x|)}$.
\end{itemize}
\end{definition}

\begin{definition}\label{opparity}
For a complexity class $C$, we define the class $\parity\cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then for all $y \in \{0,1\}^{p(|x|)}$, $g(\langle x, y\rangle) \neq \x$ and for an odd number of such $y$, $g(\langle x,y\rangle) = 1$.
\item If $f(x) = 0$ then for all $y \in \{0,1\}^{p(|x|)}$, $g(\langle x, y\rangle) \neq \x$ and for an even number of such $y$, $g(\langle x,y\rangle) = 1$.
\end{itemize}
\end{definition}

In this paper, we will want to concern ourselves mainly with $\p$ and classes that result from applying a sequence of the above operators to it. We will use the following terminology throughout.
\begin{definition}\label{constructible}
For a set $Q$ of operators, we say a complexity class $C$ is \emph{$Q$-constructible} if it is of the form $Q_k \cdot Q_{k-1} \cdots Q_{2} \cdot Q_1 \cdot \p$ for some $k$ where $Q_i \in Q$ for all $i \in \{1,\ldots,k\}$.
\end{definition}

\section{Polynomial Time Reductions}

One of the technical details that will arise in many of our results is the need for polynomial time reductions. In this section, we will establish that all $\{\Sigma,\Pi,\bp,\parity\}$-constructible complexity classes are closed under polynomial time reductions. In particular, we need

\begin{prop}
Let $C$ be a $\{\Sigma,\Pi,\bp,\parity\}$-constructible complexity class and let $T$ be a mapping $\{0,1\}^n \to \{0,1\}^m$ defined by a polynomial time Turing machine. Then if $f \in C$, $f\circ T \in C$.
\end{prop}

This follows from the following lemma:

\begin{lemma}
If $C$ is a complexity class closed under polynomial time reductions. Then $\Sigma \cdot C$, $\Pi\cdot C$, $\bp\cdot C$, and $\parity\cdot C$ are closed under polynomial time reductions.
\end{lemma}
\begin{proof}
We wish to show that if $f \in \op \cdot C$, then $f \circ T \in \op \cdot C$. We have a $g \in C$ such that $g(\langle T(x), y\rangle)$ has the correct relation to $f$ for $f$ to be in $\op \cdot C$ (for example, for $\Sigma$, if $f(T(x)) = 1$, then there is a $y$ with $g(\langle T(x), y\rangle) = 1$ and if $f(T(x)) = 0$, then for all $y$ $g(\langle T(x), y \rangle) = 0$). However, we can construct a polynomial time Turing machine that takes $\langle x, y\rangle$ to $\langle T(x), y\rangle$, so since $C$ is closed under polynomial time reductions, we have that $h(\langle x,y\rangle) = g(\langle T(x),y\rangle)$ is a function in $C$. As $h(\langle x,y\rangle)$ has the same relation to $f \circ T$ as $g$ does to $f$, we have that $f \in \op \cdot C$, as desired.
\end{proof}

\section{Basic Operator Results}

Because we will be working with complexity classes defined by sequences of operators applied to $\p$, it will be useful to have several basic results about manipulations that can be performed with operators. We will start with the ability to collapse two identical operators into one.

\begin{prop}\label{collapse}
Let $C$ be a complexity class. Then $\Sigma\cdot\Sigma\cdot C = \Sigma\cdot C$, $\Pi\cdot\Pi\cdot C = \Pi\cdot C$, and $\strongbp\cdot\strongbp\cdot C = \strongbp \cdot C$.
\end{prop}

We will also use the following results that allow in one direction the interchanging of $\strongbp$ with the other operators.

\begin{prop}\label{interchange}
Let $C$ be a complexity class. Then $\Sigma\cdot\strongbp\cdot C \subseteq \strongbp\cdot\Sigma\cdot C$, $\Pi\cdot\strongbp\cdot C \subseteq \strongbp\cdot\Pi\cdot C$, and $\parity\cdot\strongbp\cdot C \subseteq \strongbp\cdot\parity\cdot C$.
\end{prop}

All of these results are not difficult to verify.

%\section{Closed Under Intersection}
\section{Amplification of $\bp$ to $\strongbp$\label{amplifysection}}

Consider the amplification of the probabilities in the $\bp$ operator. It is well known that\linebreak $\bpp = \bp \cdot \p$ can be amplified; that is, we can replace the error probability of $1/3$ with probabilities exponentially small in the input size. Thus we can write $\bp \cdot \p = \strongbp \cdot \p$. We would like to compare $\bp \cdot C$ to $\strongbp \cdot C$ for more general complexity classes $C$.

\begin{definition}
We say that a complexity class $C$ is \emph{well-structured} if it is $\{\Sigma, \Pi, \bp, \parity\}$-constructible, and the operator $\parity$ does not appear to the left of a $\bp$ operator.
\end{definition}

The aim of this section and the next is to prove the following amplification result:

\begin{theorem}\label{amplify}
Let $C$ be a well-structured complexity class. Then \emph{$\bp \cdot C = \strongbp \cdot C$}.
\end{theorem}

Initially, this may seem to be obviously true for the same reasons that $\bp \cdot \p = \strongbp \cdot \p$. The problem is that amplification requires running some machine which accepts a language in $C$ more than once. This requires the structure of $C$ to allow for such repetitions. In particular, we will find that it is nontrivial when the $\parity$ operator is involved. The fact that we need $C$ to be well-structured rather than just any $\{\Sigma, \Pi, \bp, \parity\}$-constructible class is due to an annoying detail that will come up when we deal with oracles in Section \ref{oracle}. We will cover the non-well-structured case in Section \ref{notwellstruct}.

To show that a class is amplifiable, we need the concept of a majority reduction.
\begin{definition}\label{defmajority}
We say that a complexity class $C$ is \emph{closed under majority reductions} if for any partial function $f \in C$, the partial function $\majority(f)$ defined by
$$\majority(f)(\langle x_1, \ldots, x_k\rangle) = 
\begin{cases}1 & \text{ if the number of $i$ such that }f(x_i) = 1\text{ is at least $\frac{k}{2}$} \\
0 & \text{ if the number of $i$ such that }f(x_i) = 0\text{ is more than $\frac{k}{2}$}\\
\x & \text{ otherwise}
\end{cases}$$
is in $C$.
\end{definition}
Now, we see that majority reductions are exactly what we want for amplification:
\begin{lemma}\label{majorityimpliesamplify}
If $C$ is a complexity class which is closed under majority reductions and polynomial time reductions, then \emph{$f\in\strongbp \cdot C$.}
\end{lemma}
\begin{proof}
This is now the same application of the Chernoff bound which shows that $\bp \cdot \p = \strongbp \cdot \p$. Suppose $f$ is a partial function in $\bp \cdot C$. Then there is a partial function $g$ in $C$ such that $\pr_y [g(\langle x,y\rangle) = 1] > 2/3$ if $f(x) = 1$ and $\pr_y [g(\langle x, y\rangle) = 0] > 2/3$ if $f(x) = 0$, where the length of $y$ is equal to $p(|x|)$ for some polynomial $p$. Let $q$ be a polynomial, where $e^{-q(|x|)}$ is the desired error probability. Let $k = 48q(|x|)$.

Here is how we determine the value $f(x)$ with error probability $e^{-q(|x|)}$. Choose $k$ strings $y_1,y_2,...,y_k$ randomly, then return $h(\langle x, y_1y_2\cdots y_k\rangle) = \majority(g)(\langle \langle x, y_1 \rangle, \langle x, y_2 \rangle, \ldots, \langle x, y_k \rangle \rangle)$. Notice that $h$ can be easily reduced to $\majority(g)$ in polynomial time, and is therefore in $C$.
Let $X_i$ be an indicator variable which is $1$ if $g(\langle x,y_i\rangle)$ agrees with $f(x)$. We have that the $X_i$ are independent Bernoulli random variables with $\pr\left[X_i = 1\right] > \frac{2}{3}$.  Then by the Chernoff bound,
\begin{align*}
\pr\left[\sum X_i < k/2\right] &= \pr\left[\sum X_i < (1 - 1/4)(2k/3)\right]\\
&< e^{-(1/4)^2 (2k/3) / 2}\\
&= e^{-q(|x|)} \\
&< 2^{-q(|x|)}
\end{align*}
We can do this for any polynomial $q$, so $f \in \strongbp \cdot C$. Thus, $\bp \cdot C = \strongbp \cdot C$.
\end{proof}

Thus, in order to prove Theorem \ref{amplify}, we just need to show that any well-structured complexity class is closed under majority reductions. In order to show that these are closed under majority reductions, we will need the help of another property:
\begin{definition}\label{defintersection}
We say that a complexity class $C$ is \emph{closed under intersection} if for any partial function $f \in C$, the partial function $\intersect(f)$ defined by
$$\intersect(f)(\langle x_1, \ldots, x_k\rangle) = 
\begin{cases}1 & \text{ if $f(x_i) = 1$ for all $i$} \\
0 & \text{ if there exists some $i$ for which $f(x_i) = 0$}\\
\x & \text{ otherwise}
\end{cases}$$
is in $C$.
%We say that a class $C$ is \emph{closed under intersection} if for any language $L \in C$, the language $\intersection(L) = \{(x_1,...,x_k) : k\in\mathbb{N}, x_i \in L_i ~ \forall i\}$ is in $C$.
\end{definition}
We will demonstrate that all well-structured complexity classes are closed under intersection and under majority reductions. To do this, we will use induction on the number of operators in $C$. Clearly $\p$ is closed under intersection and majority reductions. Thus, the result follows from the following two lemmas:

\begin{lemma}\label{intersectionlemma}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. If $C$ is closed under majority reductions and under intersection, then (i) \emph{$\Sigma \cdot C$}, (ii) \emph{$\Pi \cdot C$}, (iii) \emph{$\bp \cdot C$}, and (iv) \emph{$\parity \cdot C$} are all closed under intersection.
%Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. Then $C$ is closed under intersection.
\end{lemma}

\begin{lemma}\label{amplifymainlemma}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class class. If $C$ is closed under majority reductions, then (i) \emph{$\Sigma \cdot C$}, (ii) \emph{$\Pi \cdot C$}, and (iii) \emph{$\bp \cdot C$} are closed under majority reductions. Furthermore, (iv) \emph{$\parity \cdot C$} is closed under majority reductions if $C$ is $\{\Sigma, \Pi, \parity\}$-constructible.
\end{lemma}
We begin with the proof of Lemma \ref{intersectionlemma}
\begin{proof}[Proof of Lemma \ref{intersectionlemma}]
\begin{enumerate}
\item[]
\item[(i)] Suppose $f$ is a partial function in $\Sigma\cdot C$. Then there exists a partial function $g\in C$ and a polynomial $p$ such that $f(x) = 1$ if there exists some $y$ with $|y| = p(|x|)$ such that $g(\langle x,y\rangle) = 1$, and $f(x) = 0$ if for all $y$ with $|y| = p(|x|)$ we have $g(\langle x, y\rangle) = 0$. Now, we want to show that $\intersect(f) \in \Sigma \cdot C$. Now, $\intersect(f)(\langle x_1,...,x_k\rangle) = 1$ if and only if there exist $y_1,...,y_k$ such that $g(\langle x_i, y_i\rangle) = 1$ for all $i$, which is equivalent to saying that $\intersect(g)(\langle \langle x_1,y_1\rangle,...,\langle x_k,y_k\rangle\rangle) = 1$. Similarly, $\intersect(f)(\langle x_1,...,x_k\rangle) = 0$ if and only if for all $y_1,...,y_k$, we have $\intersect(g)(\langle \langle x_1,y_1\rangle,...,\langle x_k,y_k\rangle\rangle) = 0$. Thus, $\intersect(f) \in \Sigma \cdot C$.

%To do this, we just guess a $k$-tuple $(y_1,y_2,...,y_k)$, and then check if $M$ accepts $(x_1, y_1)$, $(x_2, y_2)$, ..., and $(x_k, y_k)$. This is equivalent to checking that $((x_1,y_1),(x_2,y_2),...,(x_k,y_k)) \in \intersect(M)$, and by assumption, $\intersect(M)$ is in $C$ since $M$ is in $C$.

\item[(ii)] The proof for $\Pi \cdot C$ is analogous to the proof for $\Sigma \cdot C$.

%\item[(iii)] Now we consider $\bp \cdot C$. By assumption, $C$ is closed under majority reductions, so by Lemma \ref{majorityimpliesamplify}, $\bp \cdot C = \strongbp \cdot C$. If we take any language $L \in \bp \cdot C$, we find that $L \in \strongbp \cdot C$. Therefore, there exists a $C$ machine $M$ such that $x\in L$ if and only if
%\begin{center}
%$\displaystyle \pr_y [M(x,y)\text{ accepts}] > $
%\end{center}

\item[(iii)] Now we consider $\bp \cdot C$. Let $f$ be a partial function in $\bp \cdot C$. Then, there is some partial function $g \in C$ and a polynomial $p$ such that $\pr_y[f(x) = g(\langle x,y\rangle)] > 2/3$ if $f(x) \ne \x$, where $y$ is chosen as a random string of length $p(|x|)$.

By assumption, $C$ is closed under majority reductions and under intersection. Thus,\linebreak $\intersect(\majority(g)) \in C$. We want to show that $\intersect(f) \in \bp\cdot C$. For any $(x_1,x_2,...,x_k)$, we randomly choose random strings $y_{i,j}$ of length $p(|x_i|)$, for $1\le i\le k$ and $j\le 1\le \ell$, where $\ell = \lceil -48\ln(1 - (2/3)^{1/k}) \rceil$. Then, we check $\intersect(\majority(g))(\langle X_1, X_2, ..., X_k\rangle)$, where
\begin{center}
$X_i = \langle\langle x_i,y_{i,1}\rangle,\langle x_{i},y_{i,2}\rangle,...,\langle x_{i},y_{i,\ell}\rangle\rangle$.
\end{center}
By the Chernoff bound, as in the proof of Lemma \ref{majorityimpliesamplify}, we have that $\majority(M)(X_i) = f(x_i)$ with probability greater than $e^{-(1/4)^2 (2\ell/3)/2} \ge 1 - (2/3)^{1/k}$. If $f(x_i) = 1$ for all $i$, then the probability that there exists some $i$ for which $\majority(g)(X_i) \ne 1$ is therefore greater than $((2/3)^{1/k})^k = 2/3$. If there is some $i$ for which $f(x_i) = 0$, then there is a $1 - (2/3)^{1/k} \ge 2/3$ chance that $\majority(g)(X_i) = 0$.

Thus, we get that $\intersect(\majority(g))(\langle X_1,...,X_k\rangle) = \intersect(f)(\langle x_1,...,x_k\rangle)$ with probability at least $2/3$. Therefore, since $\intersect(\majority(g)) \in C$, we get that $\intersect(f) \in \bp \cdot C$, so $\bp \cdot C$ is closed under intersection.

%Thus, we get that $(X_1,...,X_k)\in\intersect(\majority(M))$ with probability greater than $2/3$ if $(x_1,x_2,...,x_k)\in L$, and $(X_1,...,X_k)\not\in\intersect(\majority(M))$ with probability greater than $2/3$ if $(x_1,x_2,...,x_k)\not\in L$. Therefore, $\intersect(L) \in \bp \cdot C$, so $\bp \cdot C$ is closed under intersection.

\item[(iv)] Finally, we consider $\parity \cdot C$. If $f \in \parity \cdot C$, then there is a partial function $g \in C$ and a polynomial $p$ such that $f(x) = 1$ if and only if an odd number of $y \in \{0,1\}^{p(|x|)}$ and are such that $g(\langle x, y\rangle) = 1$, and $f(x) = 0$ if and only if there are an even number (but if $g(\langle x,y\rangle) = \x$ for any $y$, then $f(x) = \x$). We want to show that $\intersect(f)$ is in $\parity \cdot C$. Say we have $x_1,x_2,...,x_k$ and we need to verify that all of them are in $f$. Then, accept if there are an odd number of sequences $y_1,y_2,...,y_k$ such that $\intersect(g)(\langle\langle x_1,y_1\rangle,\langle x_2,y_2\rangle,...,\langle x_k,y_k\rangle\rangle) = 1$. To see why this works, let $\# x_i$ be the number of $y_i$ for which $g(\langle x_i,y_i\rangle) = 1$. Then, the number of sequences $y_1,y_2,...,y_k$ for which $\intersect(g)(\langle\langle x_1,y_1\rangle,\langle x_2,y_2\rangle,...,\langle x_k,y_k\rangle\rangle) = 1$ is equal to $(\# x_1)(\# x_2)...(\# x_k)$ which is odd if and only if $\# x_i$ is odd for all $i$.
\end{enumerate}
\end{proof}

\begin{proof}[Proof of Lemma \ref{amplifymainlemma} (i,ii,iii)]

 The proofs of (i), (ii), and (iii) are similar to the proofs in Lemma \ref{intersectionlemma}. Part (iv) is the most difficult, and will not be finished until Section \ref{oracle}.
\begin{enumerate}
\item[(i)] Suppose $f$ is a partial function in $\Sigma\cdot C$. Then there exists a partial function $g\in C$ and a polynomial $p$ such that $f(x) = 1$ if there exists some $y$ with $|y| = p(|x|)$ such that $g(\langle x,y\rangle) = 1$, and $f(x) = 0$ if for all $y$ with $|y| = p(|x|)$ we have $g(\langle x, y\rangle) = 0$. Now, we want to show that $\majority(f) \in \Sigma \cdot C$. Now, $\majority(f)(\langle x_1,...,x_k\rangle) = 1$ if and only if there exist $y_1,...,y_k$ such that $g(\langle x_i, y_i\rangle) = 1$ for at least half of the $i$, which is equivalent to saying that $\majority(g)(\langle \langle x_1,y_1\rangle,...,\langle x_k,y_k\rangle\rangle) = 1$. Similarly, $\majority(f)(\langle x_1,...,x_k\rangle) = 0$ if and only if for more all $y_1,...,y_k$, we have $\majority(g)(\langle \langle x_1,y_1\rangle,...,\langle x_k,y_k\rangle\rangle) = 0$. Thus, $\majority(f) \in \Sigma \cdot C$.

%Suppose $L \in \Sigma \cdot C$. Then there exists a language $M \in C$ and a polynomial $p$ such that $x\in L$ if and only if there exists some $y$ with $|y| = p(x)$ such that $(x,y) \in M$. Now, we want to show that $\intersect(L) \in \Sigma \cdot C$; that is, given a $k$-tuple $(x_1,x_2,...,x_k)$, we want to determine if at least half of the $x_i$ are in $L$ using the power of $\Sigma \cdot C$. To do this, just guess a $k$-tuple $(y_1,y_2,...,y_k)$ with $|y_i| = p(|x_i)|$ and then check if $((x_1,y_1),(x_2,y_2),...,(x_k,y_k)) \in \majority(M)$. Since $C$ is closed under majority reductions, $\majority(M) \in C$. There exists such $y_i$'s if and only if a majority of the $x_i$ are in $L$.
\item[(ii)] The proof for $\Pi \cdot C$ is analogous to the proof for $\Sigma \cdot C$.
\item[(iii)] Now we consider $\bp \cdot C$. Let $f$ be a partial function in $\bp \cdot C$. Then there exists a partial function $g \in C$ and a polynomial $p$ such that if $y \in \{0,1\}^{p(|x|)}$ is chosen as a random string, then $\pr[f(x) = g(\langle x,y\rangle)] > 2/3$ if $f(x) \ne \x$.

%\begin{center}
%$\pr[M\text{ accepts }(x,y)] > 2/3$ if $L$ accepts $x$,\\
%$\pr[M\text{ rejects }(x,y)] > 2/3$ if $L$ rejects $x$.
%\end{center}
For any $\langle x_1,x_2,...,x_k\rangle$, we randomly choose random strings $y_{i,j}$ of length $p(|x_i|)$, for $1\le i\le k$ and $j\le 1\le \ell$, where $\ell = \lceil -48\ln(1 - (2/3)^{1/k}) \rceil$.
Now, $\majority(\majority(g)) \in C$, since $C$ is closed under majority reductions. By the Chernoff bound, (as in Lemma \ref{intersectionlemma}) there is at least a $1-(2/3)^{1/k}$ probability that some $X_i = \langle\langle x_i,y_{i,1}\rangle, \langle x_i, y_{i,2}\rangle,...,\langle x_i, x_{i,\ell}\rangle\rangle$ is ``correct," by which we mean that $\majority(g)(X_i) = f(x_i)$.

Thus, there is at least a $2/3$ chance that \begin{center}$\majority(\majority(g))(\langle X_1,X_2,...,X_k\rangle) = \majority(f)(\langle x_1,x_2,...,x_k\rangle)$.\end{center} Therefore, $\majority(f) \in \bp \cdot C$.
\end{enumerate}
\end{proof}

\section{An Oracle Result}\label{oracle}

To complete the proof of Lemma \ref{amplifymainlemma} (iv), we use the following generalization of a result in \cite{Toda}, which is that $\parity \cdot (\p ^{\parity\cdot\p}) = \parity\cdot\p$, a fact which is used to show that $\parity \cdot \p$ is closed under majority reductions. Proving this fact is the main reason that we need the fact that the $\{\Sigma, \Pi, \bp, \parity\}$-constructible classes are closed under intersection.

\begin{theorem}\label{oracleparityc}
%Let $C$ be a class containing \emph{$\p$} which is closed under intersection. Then\linebreak \emph{$\parity \cdot (\p^{\parity \cdot C}) = \parity \cdot C$}.
%Let $C$ be a $\{\Sigma,\Pi,\parity\}$-constructible class. Then \emph{$ \p^{\parity \cdot C} = \parity \cdot C$}.
Let $C$ be a class containing \emph{$\p$} which is closed under intersection and such that every function in $C$ is defined everywhere (no \emph{$\x$}'s). Then \emph{$ \p^{\parity \cdot C} = \parity \cdot C$}.
\end{theorem}
\begin{proof}
The direction $\parity \cdot C \subseteq \p^{\parity \cdot C}$ is trivial. Let us consider the interesting direction\linebreak $\p^{\parity \cdot C}\subseteq \parity\cdot C$.

Suppose $f \in \parity \cdot (P^{\parity\cdot C})$. Then, there is some polynomial time turing machine $T$, equipped with an oracle to some function $g\in \parity\cdot C$, which accepts $x$ if $f(x) = 1$ and rejects $x$ if $f(x) = 0$.

To show that $f$ lies in $\parity\cdot C$, the basic idea is to ``guess" the answers to the oracle calls, and then check them. We make it so that we get an odd number of solutions whenever we guess correctly, and an even number of solutions otherwise.

%We use instead a Turing machine $T'$ which makes oracle calls to the language $M'$, defined as follows. For an input $x$, with $|x| \ge 2$, $M'$ accepts $x$ if either
%\begin{itemize}
%\item $x$ consists only of $0$'s.
%\item $x$ begins with a $1$, and $M$ would accept the last $|x| - 2$ bits.
%\end{itemize}
There exists a polynomial $p$ such that $T$ always makes at most $p(|x|)$ oracle calls. There is a polynomial $q(|x|)$ which bounds the input length of any query made to an oracle.

Each oracle call queries some input to check if it is $g$. There is a function $h \in C$ and a polynomial $r$ such that $g(x) = 1$ if and only if $h(\langle x,y\rangle) = 1$ for an odd number of $y\in\{0,1\}^{r(|x|)}$, and $g(x) = 0$ otherwise. Thus, $f \in \parity \cdot C$.

To show that $f$ is in $\parity \cdot C$, we guess the following bits for a given input $x$:
\begin{itemize}
\item Bits $a_1,a_2,...,a_{p(|x|)}$. Intuitively, these will be the answers to the oracle calls made by $T$.
\item Bits $b_1,b_2,...,b_{p(|x|)}$. The purpose of these will become clear later.
\item Strings $y_1,y_2,...,y_{p(|x|)}$, each of length $r(q(|x|))$. These are the strings that an oracle call guesses.
\end{itemize}
After guessing, we do the following polynomial time reduction to $\intersect(h)$. For an input $x$, simulate $T$ using the bits $a_1,a_2,...,a_{p(|x|)}$ as the answers to the oracle calls (taking $1$ to mean that the oracle call accepted, and $0$ to mean that the oracle call rejected). If $T$ would reject, then reject.

Also find the strings $x_1,x_2,...,x_{p(|x|)}$ which are the inputs that $T$ would query to the oracles. These may depend on the $a_i$. We now want to verify that the oracle calls are correct. Say that $(a_i, b_i, y_i)$ is \emph{good} if either
\begin{itemize}
\item $b_i = 0$, and both $a_i = 0$ and $y_i = 0^{r(q(|x|))}$, or
\item $b_i = 1$ and $h(x_i, y_i)$
\end{itemize}
Reject if any $(a_i, b_i, y_i)$ is not good. To determine if they are all good, we will have to check some pairs $(x_i, y_i)$ to see if $\overline{h}(x_i,y_i) = 1$. We can do this with a call to $\intersect(h)$.

(Technical note: it is possible that some bits out of the $a_i$, $b_i$, and $y_i$ are not used. It is possible that not all $p(x)$ oracle calls will be made, or that not all $r(q(|x|))$ bits of a $y_i$ will be used, if $|x_i| < q(|x|)$. Thus, we also say that $(a_i, b_i, y_i)$ is not good if any unused bits are nonzero.)

Why does this give us what we want? We want to show that this will accept for an odd number of choices of the $a_i$, $b_i$, and $y_i$ if and only if $f(x) = 1$. Let $\# (a_1,...,a_{p(|x|)})$ be the number of ways to choose the $b_i$, and $y_i$ such that all triples $(a_i,b_i,y_i)$ are good. Then the total number of accepting paths is
\begin{center}$\displaystyle \sum_{a_1,...,a_{p(|x|)}\text{ such that $T$ accepts}}  \#(a_1,...,a_{p(|x|)})$\end{center}
We claim that $ \#(a_1,...,a_{p(|x|)})$ is odd if and only if $a_1,a_2,...,a_{p(|x|)}$ are the correct answers to the oracle calls. This follows from the way we chose to decide if $(a_i, b_i, y_i)$ is good. If $a_1,a_2,...,a_{p(|x|)}$ are the correct answers to the oracle calls, then for each $i$, there are an odd number of $(b_i,y_i)$ such that $(a_i, b_i, y_i)$ is good. If $a_i = 1$, all good triples will have $b_i = 1$, so the parity is determined by the number of $y_i$ for which $P$ accepts $(x_i, y_i)$. But if $a_i = 1$, then this should be odd. If $a_i = 0$, then the number of $y_i$ for which $P$ accepts $(x_i, y_i)$ is even. However, we get one more good pair, namely $(0,0,0)$.

On the other hand, if any $a_i$ is incorrect, then the first such incorrect answer will have an even number of good triples.

Hence, the sum will be odd if and only if $T$ accepts when the oracle calls are correct. Therefore, $f(x) = 1$ if and only if this accepts for an odd number of choices of all the $a_i$, $b_i$, and $y_i$.

%Hence, the sum will be odd if and only if $T$ accepts when the oracle calls are correct. Therefore, $L$ accepts $x$ if and only if this accepts for an odd number of choices of all the $a_i$, $b_i$, and $y_i$, and $L$ rejects $x$ otherwise. Thus, $L \in \parity \cdot C$. This is true for any $L \in \p^{\parity \cdot C}$, so $\p^{\parity \cdot C} \subseteq \parity \cdot C$.
\end{proof}
%\begin{remark}\emph{
%While this paper applies Theorem \ref{oracle} only in the case where $C$ is $\{\Sigma,\Pi,\bp,\parity\}$-constructible, it can also be used to show, for instance, that $\p^{\parity \cdot \pp} = \parity \cdot \pp$, although it is nontrivial to show that $\pp$ is closed under intersection. For a proof, see \cite{Beigel}.
%}\end{remark}

We can use this remarkable fact to finish the proof of Lemma \ref{amplifymainlemma}, thus proving Theorem \ref{amplify}.
\begin{proof}[Proof of Lemma \ref{amplifymainlemma} (iv)]
Take any function $f \in \parity \cdot C$. If $C$ is $\{\Sigma, \Pi, \parity\}$-constructible, we can extend $f$ to some $\overline{f}$ which is defined everywhere; i.e. $\overline{f}(x) \ne \x$ for all $x$. To extend $f$ in this way, we simply extend the innermost $\p$ function (see Remark \ref{equivtoold}).

Now, we will show that $\majority(\overline{f})$ is in $\parity \cdot C$. It is easy to see that $\majority(\overline{f}) \in \p^{\parity \cdot C}$. For a given $k$-tuple $(x_1,x_2,...,x_k)$, we use the oracle call to $\parity \cdot C$ to determine how many of the $x_i$ are such that $\overline{f}(x) = 1$ and how many are such that $\overline{f}(x) = 0$. If at least half are accepted, we accept, and if more than half are rejected, we reject.

Thus, $\majority(\overline{f}) \in \p^{\parity \cdot C}$. Thus, we can apply Theorem \ref{oracleparityc} to get that $\majority(\overline{f}) \in \parity \cdot C$. But $\majority(\overline{f})$ is just an extension of $\majority(f)$, so $\majority(f) \in \parity \cdot C$. Therefore $\parity \cdot C$ is closed under majority reductions.
\end{proof}

\section{The non-well-structured case}\label{notwellstruct}

\section{Conclusion}

\pagebreak

\begin{thebibliography}{9}

%\bibitem{Beigel} Beigel, R., Reingold, N., and Spielman, D.A. \emph{PP is closed under intersection}, Proceedings of ACM Symposium on Theory of Computing 1991, pp. 1-9, 1991.

\bibitem{Schoning} Sch\"oning, U. \emph{Probabilitistic complexity classes and lowness}, Proceedings of the 2nd IEEE Conference on Structure in Complexity Theory, 1987, pp. 2-8.

\bibitem{Schoning2} Sch\"oning, U. \emph{The power of counting}, Proceedings of the 3rd IEEE Conference on Structure in Complexity Theory, 1988, pp. 2-9.

\bibitem{Toda}Toda, S. \emph{PP is as Hard as the Polynomial-Time Hierarchy.} Siam Journal of Computing. Vol. 20, No. 5, pp. 865-877. Oct 1991.

\bibitem{Toda2} Toda, S. and Ogiwara, M. \emph{Counting classes are at least as hard as the polynomial-time hierarchy,} Structure in Complexity Theory Conference, 1991, Proceedings of the Sixth Annual, pp. 2-12, 30 Jun-3 Jul 1991.

\end{thebibliography}

\end{document}

