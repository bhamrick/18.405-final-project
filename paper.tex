
\documentclass[11pt]{article}

\usepackage[latin1]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{url}
\usepackage[breaklinks=true,hyperref]{hyperref}
\usepackage{amssymb}
\usepackage[dvips]{color}
\usepackage{epsfig}
\usepackage{mathrsfs}
\usepackage{indentfirst}
\usepackage{subfig}

\include{header}

\newcommand{\pr}{\text{Pr}}

\newcommand{\bp}{\textsf{BP}}
\newcommand{\strongbp}{\widehat{\textsf{BP}}}
%\newcommand{\strongbp}{\textsf{strongBP}}
\newcommand{\bpp}{\textsf{BPP}}
\newcommand{\parity}{\oplus}
\newcommand{\p}{\textsf{P}}
\newcommand{\op}{\textsf{Op}}
\newcommand{\pp}{\textsf{PP}}
\newcommand{\np}{\textsf{NP}}
\newcommand{\conp}{\textsf{coNP}}
\newcommand{\x}{\textsf{X}}
\newcommand{\intersection}{\textsf{intersect}}
\newcommand{\intersect}{\textsf{intersect}}
\newcommand{\majority}{\textsf{majority}}

\begin{document}

\begin{center} \begin{LARGE} {\sc \bf Amplification with Operators on Complexity Classes} \vspace{6pt}

{\sc 18.405 Final Paper, Spring 2011} \vspace{9pt}

\end{LARGE} { \Large \textsc{Brian Hamrick and Travis Hance}}

\end{center}

\section{Introduction}

\section{Definitions}

\subsection{Partial Functions}

Complexity classes are usually defined in terms of \emph{languages}. A language $L$ is a subset of $\bigcup_{n=0}^{\infty}\{0,1\}^n$, which can also be viewed as a function $f_L: \bigcup_{n=0}^{\infty}\{0,1\}^n \to \{0,1\}$, where $f_L(x) = 1$ if and only if $x \in L$. However, the definitions of some complexity classes in terms of languages leads to undesirable consequences. For example, the standard definition of $\bpp$ means that a ``$\bpp$-machine'' must accept \emph{every} input with probability outside the range $[\frac{1}{3},\frac{2}{3}]$, but nearly every natural problem whose solution is described as a $\bpp$ algorithm in fact has a promise associated. The concept of a partial function is a natural way to resolve this issue.

\begin{definition}\label{partialfunction}
A \emph{partial function} is a function $f: \bigcup_{n=0}^{\infty}\{0,1\}^n \to \{0,1,\x\}$.
\end{definition}

\subsection{Complexity Classes}

For the entirety of this paper, we will use the following definitions of a complexity class and $\p$.

\begin{definition}\label{complexityclass}
A \emph{complexity class} is a set of partial functions.
\end{definition}

\begin{definition}\label{p}
The complexity class $\p$ is the set of partial functions such that $f \in \p$ if and only if there exists a polynomial $p$ and a Turing machine $T$ such that:
\begin{itemize}
\item If $f(x) = 1$, then $T$ halts after at most $p(|x|)$ steps and accepts.
\item If $f(x) = 0$, then $T$ halts after at most $p(|x|)$ steps and rejects.
\end{itemize}
\end{definition}

Notice that there is no restriction on $T$ if $f(x) = \x$. However, this definition of $\p$ can be reconciled with the standard definition of $\p$ in the following way.

\begin{remark}
For every partial function $f \in \p$, there exists another partial function $L \in \p$ such that
\begin{itemize}
\item For all $x$, $L(x) = 0$ or $L(x) = 1$.
\item If $f(x) = 1$, then $L(x) = 1$.
\item If $f(x) = 0$, then $L(x) = 0$.
\end{itemize}
\end{remark}

To see this, consider simulating $T$ and cutting it off after $p(|x|)$ steps, which is followed by a rejection. In this statement, we can see $L$ as a language in the standard complexity class $\p$, so effectively any partial function can be extended to a language.

\subsection{Operators}

In this paper we focus on four operators on complexity classes: $\Sigma, \Pi, \bp, \parity$ which are defined in analogy to the relationship between $\p$ and the classes $\np$, $\conp$, $\bpp$, and $\parity\p$. For all of these definitions, we let $\langle x, y\rangle$ denote a single string of size $O(|x| + |y|)$ that represents the pair $(x,y)$. Additionally, we define a strengthened version of the $\bp$ operator, $\strongbp$, which guarantees amplification style results. We will show in section \ref{amplifysection} that for most of the classes we consider, these operators give the same result.

\begin{definition}\label{opsigma}
For a complexity class $C$, we define the class $\Sigma \cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then there exists a $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x,y \rangle) = 1$.
\item If $f(x) = 0$ then for every $y \in \{0,1\}^{p(|x|)}$, we have $g(\langle x, y\rangle) = 0$.
\end{itemize}
\end{definition}

\begin{definition}\label{oppi}
For a complexity class $C$, we define the class $\Pi \cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then for every $y \in \{0,1\}^{p(|x|)}$, we have $g(\langle x,y \rangle) = 1$.
\item If $f(x) = 0$ then there exists $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 0$.
\end{itemize}
\end{definition}

\begin{definition}\label{opbp}
For a complexity class $C$, we define the class $\bp\cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 1$ is at least $\frac{2}{3}\cdot 2^{p(|x|)}$.
\item If $f(x) = 0$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y\rangle) = 0$ is at least $\frac{2}{3}\cdot 2^{p(|x|)}$.
\end{itemize}
\end{definition}

\begin{definition}\label{opstrongbp}
For a complexity class $C$, we define the class $\strongbp\cdot C$ as the set of partial functions $f$ such that for every polynomial $q(n)$, there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y \rangle) = 1$ is at least \linebreak$\left(1 - \frac{1}{2^{q(|x|)}}\right)\cdot 2^{p(|x|)}$.
\item If $f(x) = 0$ then the number of $y \in \{0,1\}^{p(|x|)}$ such that $g(\langle x, y \rangle) = 0$ is at least \linebreak$\left(1 - \frac{1}{2^{q(|x|)}}\right)\cdot 2^{p(|x|)}$.
\end{itemize}
\end{definition}

\begin{definition}\label{opparity}
For a complexity class $C$, we define the class $\parity\cdot C$ as the set of partial functions $f$ such that there exists a partial function $g \in C$ and a polynomial $p(n)$ such that
\begin{itemize}
\item If $f(x) = 1$ then for all $y \in \{0,1\}^{p(|x|)}$, $g(\langle x, y\rangle) \neq \x$ and for an odd number of such $y$, $g(\langle x,y\rangle) = 1$.
\item If $f(x) = 0$ then for all $y \in \{0,1\}^{p(|x|)}$, $g(\langle x, y\rangle) \neq \x$ and for an even number of such $y$, $g(\langle x,y\rangle) = 1$.
\end{itemize}
\end{definition}

In this paper, we will want to concern ourselves mainly with $\p$ and classes that result from applying a sequence of the above operators to it. We will use the following terminology throughout.
\begin{definition}\label{constructible}
For a set $Q$ of operators, we say a complexity class $C$ is \emph{$Q$-constructible} if it is of the form $Q_k \cdot Q_{k-1} \cdots Q_{2} \cdot Q_1 \cdot \p$ for some $k$ where $Q_i \in Q$ for all $i \in \{1,\ldots,k\}$.
\end{definition}

%\section{Closed Under Intersection}
\section{Amplification of $\bp$ to $\strongbp$\label{amplifysection}}

Consider the amplification of the probabilities in the $\bp$ operator. It is well known that\linebreak $\bpp = \bp \cdot \p$ can be amplified; that is, we can replace the error probability of $1/3$ with probabilities exponentially small in the input size. Thus we can write $\bp \cdot \p = \strongbp \cdot \p$. We would like to compare $\bp \cdot C$ to $\strongbp \cdot C$ for more general complexity classes $C$.

The aim of this section and the next is to prove the following amplification result:

\begin{theorem}\label{amplify}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. Then \emph{$\bp \cdot C = \strongbp \cdot C$}.
\end{theorem}
Initially, this may seem to be obviously true for the same reasons that $\bp \cdot \p = \strongbp \cdot \bp$. The problem is that amplification requires running some machine which accepts a language in $C$ more than once. This requires the structure of $C$ to allow for such repetitions. This brings us to the concept of majority reductions.
\begin{definition}\label{defmajority}
We say that a complexity class $C$ is \emph{closed under majority reductions} if for any language $L$, the language $\majority(L) = \{(x_1,...,x_k) : k \in \mathbb{N}, |\{x_i : x_i \in L\}| \ge k/2\}$ is in $C$.
\end{definition}
Now, we see that majority reductions are exactly what we want for amplification:
\begin{lemma}\label{majorityimpliesamplify}
If $C$ is a complexity class which is closed under majority reductions, then\linebreak \emph{$\bp \cdot C = \strongbp \cdot C$.}
\end{lemma}
\begin{proof}
This is now the same application of the Chernoff bound which shows that $\bp \cdot \p = \strongbp \cdot \p$. Suppose $L$ is a language in $\bp \cdot C$. Then there is a language $M$ in $C$ such that $\pr_y [(x,y) \in M] > 2/3$ if $x\in L$ and $\pr_y [(x,y)\in M] < 1/3$ if $x\not\in L$, where the length of $y$ is polynomial in the length of $x$. Let $q$ be a polynomial, where $e^{-q(|x|)}$ is the desired error probability. Let $k = 48q(|x|)$.

Here is how we determine if a string $x$ is in $L$ with error probability $e^{-q(|x|)}$. Choose $k$ strings $y_1,y_2,...,y_k$ randomly. Then accept if a majority of $(x,y_1),(x,y_2),...,(x,y_k)$ are in $M$, which is possible to do since $\majority(M) \in C$. Let $X_i$ be an indicator variable which is $1$ if $(x,y_i)$ is in $M$. Then by the Chernoff bound,
\begin{align*}
\pr\left[\sum X_i < k/2\right] &= \pr\left[\sum X_i < (1 - 1/4)(2k/3)\right]\\
&< e^{-(1/4)^2 (2k/3) / 2}\\
&= e^{-q(|x|)} \\
&< 2^{-q(|x|)}
\end{align*}
We can do this for any polynomial $q$, so $L \in \strongbp \cdot C$. Hence, $\bp \cdot C = \strongbp \cdot C$.
\end{proof}

Thus, in order to prove Theorem \ref{amplify}, we just need to show that any $\{\Sigma,\Pi,\bp,\parity\}$-constructible complexity class is closed under majority reductions. In order to show that these are closed under majority reductions, we will need the help of another property:
\begin{definition}\label{defintersection}
We say that a class $C$ is \emph{closed under intersection} if for any language $L \in C$, the language $\intersection(L) = \{(x_1,...,x_k) : k\in\mathbb{N}, x_i \in L_i ~ \forall i\}$ is in $C$.
\end{definition}
We will demonstrate that all $\{\Sigma, \Pi, \bp, \parity\}$-constructible complexity classes are closed under intersection and under majority reductions. To do this, we will use induction on the number of operators in $C$. Clearly $\p$ is closed under intersection and majority reductions. Thus, the result follows from the following two lemmas:

\begin{lemma}\label{intersectionlemma}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. If $C$ is closed under majority reductions and under intersection, then (i) \emph{$\Sigma \cdot C$}, (ii) \emph{$\Pi \cdot C$}, (iii) \emph{$\bp \cdot C$}, and (iv) \emph{$\parity \cdot C$} are all closed under intersection.
%Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. Then $C$ is closed under intersection.
\end{lemma}

\begin{lemma}\label{amplifymainlemma}
Let $C$ be a \emph{$\{\Sigma,\Pi,\bp,\parity\}$}-constructible complexity class. If $C$ is closed under majority reductions, then (i) \emph{$\Sigma \cdot C$}, (ii) \emph{$\Pi \cdot C$}, (iii) \emph{$\bp \cdot C$}, and (iv) \emph{$\parity \cdot C$} are all closed under majority reductions.
\end{lemma}
We begin with the proof of Lemma \ref{intersectionlemma}
\begin{proof}[Proof of Lemma \ref{intersectionlemma}]
\begin{enumerate}
\item[]
\item[(i)] Suppose $L \in \Sigma\cdot C$. Then there exists a language $M\in C$ and a polynomial $p$ such that $x \in L$ if and only if there exists some $y$ with $|y| = p(|x|)$ such that $(x, y)\in M$. Now, we want to show that $\intersect(L) \in \Sigma \cdot C$; that is, given a $k$-tuple $(x_1,x_2,...,x_k)$, we want to determine if all $x_i$ are in $L$ using the power of $\Sigma \cdot C$. To do this, we just guess a $k$-tuple $(y_1,y_2,...,y_k)$, and then check if $M$ accepts $(x_1, y_1)$, $(x_2, y_2)$, ..., and $(x_k, y_k)$. This is equivalent to checking that $((x_1,y_1),(x_2,y_2),...,(x_k,y_k)) \in \intersect(M)$, and by assumption, $\intersect(M)$ is in $C$ since $M$ is in $C$.

\item[(ii)] The proof for $\Pi \cdot C$ is analogous to the proof for $\Sigma \cdot C$.

%\item[(iii)] Now we consider $\bp \cdot C$. By assumption, $C$ is closed under majority reductions, so by Lemma \ref{majorityimpliesamplify}, $\bp \cdot C = \strongbp \cdot C$. If we take any language $L \in \bp \cdot C$, we find that $L \in \strongbp \cdot C$. Therefore, there exists a $C$ machine $M$ such that $x\in L$ if and only if
%\begin{center}
%$\displaystyle \pr_y [M(x,y)\text{ accepts}] > $
%\end{center}

\item[(iii)] Now we consider $\bp \cdot C$. Let $L$ be a language in $\bp \cdot C$. Then, there is some language $M \in C$ and a polynomial $p$ such that $\pr_y[(x,y) \in M] > 2/3$ if $x\in L$ and $\pr_y[(x,y) \not \in M] < 1/3$ if $x\not\in L$, where $y$ is chosen as a random string of length $p(|x|)$.

By assumption, $C$ is closed under majority reductions and under intersection. Thus,\linebreak $\intersect(\majority(M)) \in C$. We want to show that $\intersect(L) \in \bp\cdot C$. For any $(x_1,x_2,...,x_k)$, we randomly choose random strings $y_{i,j}$ of length $p(|x_i|)$, for $1\le i\le k$ and $j\le 1\le \ell$, where $\ell = \lceil -48\ln(1 - (2/3)^{1/k}) \rceil$. Then, we check if $(X_1, X_2, ..., X_k)$
is in $\intersect(\majority(M))$, where
\begin{center}
$X_i = ((x_i,y_{i,1}),(x_{i},y_{i,2}),...,(x_{i},y_{i,\ell}))$.
\end{center}
By the Chernoff bound, as in the proof of Lemma \ref{majorityimpliesamplify}, we have that $X_i$ is in $\majority(M)$ with probability greater than $e^{-(1/4)^2 (2\ell/3)/2} \ge 1 - (2/3)^{1/k}$ if $x_i \in L$. If $x_i \in L$ for all $i$, then the probability that there exists some $i$ for which $X_i$ is not in $\majority(M)$ is therefore greater than $((2/3)^{1/k})^k = 2/3$. If there is some $i$ for which $x_i \not\in L$, then there is a $1 - (2/3)^{1/k} \ge 2/3$ chance that $X_i \not \in \majority(M)$.

Thus, we get that $(X_1,...,X_k)\in\intersect(\majority(M))$ with probability greater than $2/3$ if $(x_1,x_2,...,x_k)\in L$, and $(X_1,...,X_k)\not\in\intersect(\majority(M))$ with probability greater than $2/3$ if $(x_1,x_2,...,x_k)\not\in L$. Therefore, $\intersect(L) \in \bp \cdot C$, so $\bp \cdot C$ is closed under intersection.

\item[(iv)] Finally, we consider $\parity \cdot C$. If $L \in \parity \cdot C$, then there is a language $M \in C$ and a polynomial $p$ such that $x\in L$ if and only if an odd number of $(x,y)$ are in $M$ where $|y| = p(|x|)$. We want to show that $\intersect(L)$ is in $\parity \cdot C$. Say we have $x_1,x_2,...,x_k$ and we need to verify that all of them are in $L$. Then, guess $y_1,y_2,...,y_k$ and see if $((x_1,y_1),(x_2,y_2),...,(x_k,y_k))$ is in $\intersect(M)$. Accept if there are an odd number of sequences $y_1,y_2,...,y_k$ for which this accepts. To see why this works, let $\# x_i$ be the number of $y_i$ for which $(x_i, y_i) \in M$. Then, the number of sequences $y_1,y_2,...,y_k$ which will accept is equal to $(\# x_1)(\# x_2)...(\# x_k)$ which is odd if and only if $\# x_i$ is odd for all $i$.
\end{enumerate}
\end{proof}

\begin{proof}[Proof of Lemma \ref{amplifymainlemma} (i,ii,iii)]

 The proofs of (i), (ii), and (iii) are similar to the proofs in Lemma \ref{intersectionlemma}. Part (iv) is the most difficult, and will not be finished until Section \ref{oracle}.
\begin{enumerate}
\item[(i)] Suppose $L \in \Sigma \cdot C$. Then there exists a language $M \in C$ and a polynomial $p$ such that $x\in L$ if and only if there exists some $y$ with $|y| = p(x)$ such that $(x,y) \in M$. Now, we want to show that $\intersect(L) \in \Sigma \cdot C$; that is, given a $k$-tuple $(x_1,x_2,...,x_k)$, we want to determine if at least half of the $x_i$ are in $L$ using the power of $\Sigma \cdot C$. To do this, just guess a $k$-tuple $(y_1,y_2,...,y_k)$ with $|y_i| = p(|x_i)|$ and then check if $((x_1,y_1),(x_2,y_2),...,(x_k,y_k)) \in \majority(M)$. Since $C$ is closed under majority reductions, $\majority(M) \in C$. There exists such $y_i$'s if and only if a majority of the $x_i$ are in $L$.
\item[(ii)] The proof for $\Pi \cdot C$ is analogous to the proof for $\Sigma \cdot C$.
\item[(iii)] Now we consider $\bp \cdot C$. Let $L$ be a language in $\bp \cdot C$. Then there exists a language $M \in C$ and a polynomial $p$ such that if $y$ is chosen as a random string with $|y| = p(|x|)$, then
\begin{center}
$\pr[M\text{ accepts }(x,y)] > 2/3$ if $L$ accepts $x$,\\
$\pr[M\text{ rejects }(x,y)] > 2/3$ if $L$ rejects $x$.
\end{center}
For any $(x_1,x_2,...,x_k)$, we randomly choose random strings $y_{i,j}$ of length $p(|x_i|)$, for $1\le i\le k$ and $j\le 1\le \ell$, where $\ell = \lceil -48\ln(1 - (2/3)^{1/k}) \rceil$.
Now, $\majority(\majority(M)) \in C$, since $C$ is closed under majority reductions. By the Chernoff bound, (as in Lemma \ref{intersectionlemma}) there is at least a $1-(2/3)^{1/k}$ probability that some $X_i = ((x_i,y_{i,1}), (x_i, y_{i,2}),...,(x_i, x_{i,\ell}))$ is ``correct," by which we mean that $\majority(M)$ accepts $X_i$ if $L$ accepts $x_i$, and $\majority(M)$ rejects $X_i$ if $L$ rejects $x_i$.

Thus, there is at least a $2/3$ chance that $\majority(\majority(M))$ accepts $(X_1,X_2,...,X_k)$ if $\majority(L)$ accepts $(x_1,x_2,...,x_k)$, and there is at least a $2/3$ chance that $\majority(\majority(M))$ rejects $(X_1,X_2,...,X_k)$ if $\majority(L)$ rejects $(x_1,x_2,...,x_k)$. Therefore, $\majority(L) \in \bp \cdot C$.
\end{enumerate}
\end{proof}

\section{An Oracle Result}\label{oracle}

To complete the proof of Lemma \ref{amplifymainlemma} (iv), we use the following generalization of a result in \cite{Toda}, which shows that $\parity \cdot (\p ^{\parity\cdot\p}) = \parity\cdot\p$, a fact which is used to show that $\parity \cdot \p$ is closed under majority reductions.

\begin{theorem}\label{oracleparityc}
%Let $C$ be a class containing \emph{$\p$} which is closed under intersection. Then\linebreak \emph{$\parity \cdot (\p^{\parity \cdot C}) = \parity \cdot C$}.
Let $C$ be a class which is closed under intersection. Then \emph{$\parity \cdot (\p^{\parity \cdot C}) = \parity \cdot C$}.
\end{theorem}
\begin{proof}
The direction $\parity \cdot C \subseteq \parity \cdot (\p^{\parity \cdot C})$ is trivial. Let us consider the interesting direction\linebreak $\parity \cdot (\p^{\parity \cdot C})\subseteq \parity\cdot C$.

Suppose $L \in \parity \cdot (P^{\parity\cdot C})$. Then, there is some polynomial time turing machine $T$, equipped with an oracle to some language $M \in \parity\cdot C$, and some polynomial $p$, such that for any $x$, then among all $y$ with $|y| = p(|x|)$, an odd number of them are such that $T$ accepts $(x,y)$, and $T$ rejects on the rest.
\end{proof}
\begin{remark}\emph{
While this paper applies Theorem \ref{oracle} only in the case where $C$ is $\{\Sigma,\Pi,\bp,\parity\}$-constructible, it can also be used to show, for instance, that $\parity \cdot (\p^{\parity \cdot \pp}) = \parity \cdot \pp$, although it is nontrivial to show that $\pp$ is closed under intersection. For a proof, see \cite{Beigel}.
}\end{remark}

\section{Conclusion}

\pagebreak

\begin{thebibliography}{9}

\bibitem{Beigel} Beigel, R., Reingold, N., and Spielman, D.A. \emph{PP is closed under intersection}, Proceedings of ACM Symposium on Theory of Computing 1991, pp. 1-9, 1991.

\bibitem{Schoning} Sch\"oning, U. \emph{Probabilitistic complexity classes and lowness}, Proceedings of the 2nd IEEE Conference on Structure in Complexity Theory, 1987, pp. 2-8.

\bibitem{Schoning2} Sch\"oning, U. \emph{The power of counting}, Proceedings of the 3rd IEEE Conference on Structure in Complexity Theory, 1988, pp. 2-9.

\bibitem{Toda}Toda, S. \emph{PP is as Hard as the Polynomial-Time Hierarchy.} Siam Journal of Computing. Vol. 20, No. 5, pp. 865-877. Oct 1991.

\bibitem{Toda2} Toda, S. and Ogiwara, M. \emph{Counting classes are at least as hard as the polynomial-time hierarchy,} Structure in Complexity Theory Conference, 1991, Proceedings of the Sixth Annual, pp. 2-12, 30 Jun-3 Jul 1991.

\end{thebibliography}

\end{document}

